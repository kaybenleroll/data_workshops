---
title: "An Introduction to Insurance Pricing, GLMs and Model Validation"
subtitle: "Dublin Data Science"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "2017-08-24"
output:
  revealjs::revealjs_presentation:
    css: custom.css
    theme: night
    highlight: pygments
    center: true
    reveal_options:
      slideNumber: true
---

```{r knit_opts, include = FALSE}
rm(list = ls()); gc()

knitr::opts_chunk$set(tidy  = FALSE
                     ,cache = FALSE
                     ,fig.height =  8
                     ,fig.width  = 11)

library(tidyverse)
library(forcats)
library(scales)
library(purrr)
library(broom)
library(modelr)
library(poweRlaw)
library(mgcv)
library(cowplot)


options(width = 80L
       ,warn  = 1
        )

source("custom_functions.R")


set.seed(42)
```

# Background

## Computational Actuarial Science

![](img/computational_actuarial_science_cover.jpg)


## Insurance Business

\

Life Insurance

\

General Insurance

\

(Health Insurance)

---

Pay premia

\

If event occurs, receive payout


---

How do we calculate premia?

---

How *SHOULD* we calculate premia?

---

$$
\text{Price} = E(\text{Loss}) + \text{Expenses} + \text{Profit}
$$


## Life Insurance

\

Monthly or annual premia

\

Contingent annuity

\

Life Tables



## Pricing General Insurance

\

Typically 1-year policies

\

(but not always)


---

Estimate Loss Cost of a Policy

---

Frequency / Severity Model

\

Exposure vs Claims

\

Heavy use of GLMs


---

$$
\text{Price} = E[\text{Claim Rate}] \times E[\text{Claim Size}]
$$

---

Claim Rate $\longrightarrow$ Poisson

\

Claim Amount $\longrightarrow$ Gamma

---

Need policy and claim data

---

Package `CASDatasets`

\

`freMPTLfreq` and `freMPTLsev`

\

More datasets in book


# Data Loading and Exploration

```{r load_data, echo=TRUE}
library(CASdatasets)

data(freMTPLfreq)
data(freMTPLsev)
```

---

```{r show_frequency_data_head, echo=FALSE}
freMTPLfreq %>% head %>% (knitr::kable)(digits = 2)
```

---

```{r show_frequency_data_glimpse, echo=FALSE}
freMTPLfreq %>% glimpse
```

---

```{r show_severity_data_head, echo=FALSE}
freMTPLsev %>% head(n = 15) %>% (knitr::kable)(digits = 2)
```


## Combine Tables


```{r basic_data_transforms, echo=FALSE}
policy_tbl <- freMTPLfreq %>% as_data_frame
claim_tbl  <- freMTPLsev  %>% as_data_frame

names(policy_tbl) <- policy_tbl %>% names %>% clean_names
names(claim_tbl)  <- claim_tbl  %>% names %>% clean_names
```

```{r combine_policies_claims, echo=TRUE}
policy_claims_tbl <- claim_tbl %>%
    group_by(policy_id) %>%
    summarise(claim_count = n()
             ,claim_total = sum(claim_amount))

combined_tbl <- policy_tbl %>%
    left_join(policy_claims_tbl, by = 'policy_id') %>%
    mutate(claim_count = ifelse(is.na(claim_count), 0, claim_count)
          ,claim_total = ifelse(is.na(claim_total), 0, claim_total)
           )
```

---

```{r combined_table, echo=FALSE}
combined_tbl %>% head %>% (knitr::kable)(digits = 2)
```

---

```{r combined_table_dataclean, echo=TRUE}
combined_tbl %>% filter(claim_nb != claim_count)
```


## Univariate Data Exploration

\

Look at each variable

\

Create histograms, bar charts etc

\

`dataexpks` - data exploration template

---

### claim_count

```{r explore_claim_count, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Counts per Policy")
```

---

```{r explore_claim_count_nonzero, echo=FALSE, fig.height=8, fig.width=11}
ggplot(combined_tbl %>% filter(claim_count > 0)) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Counts per Policy with Claims")
```

---

### claim_amount

```{r explore_claim_amount, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(claim_tbl) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Amount") +
    ylab("Policy Count") +
    ggtitle("Histogram of Claim Amounts")
```

---

```{r explore_claim_amount_operational, echo=FALSE, fig.height=8, fig.width=11}
ggplot(claim_tbl %>% filter(claim_amount <= 25000)) +
    geom_histogram(aes(x = claim_amount), bins = 50) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claim Amount") +
    ylab("Policy Count") +
    ggtitle("Histogram of Non-Large Claim Amounts")
```

---


### exposure

```{r explore_exposure, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = exposure), bins = 50) +
    scale_y_continuous(labels = comma) +
    xlab("Policy Exposure") +
    ylab("Policy Count") +
    ggtitle("Histogram of Exposures in Policies")
```

---

### driver_age

```{r explore_driver_age, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = driver_age), bins = 30) +
    scale_y_continuous(labels = comma) +
    xlab("Driver Age") +
    ylab("Policy Count") +
    ggtitle("Histogram of Driver Ages")
```

---

### car_age

```{r explore_car_age, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_histogram(aes(x = car_age), bins = 50) +
    scale_y_continuous(labels = comma) +
    xlab("Car Age") +
    ylab("Policy Count") +
    ggtitle("Histogram of Car Age")
```





## Bivariate Data Exploration

\

Look at two variables at once

\

Boxplots, Scatterplots, Heatmaps, etc


---

### claim_count vs driver_age

```{r boxplot_driver_age_claim_count, echo=FALSE, fig.height=7.5, fig.width = 11}
ggplot(combined_tbl) +
    geom_boxplot(aes(x = claim_count %>% as.character, y = driver_age)) +
    xlab("Claim Count") +
    ylab("Driver Age") +
    ggtitle("Boxplot of Driver Ages by Claim Count")
```

---

### claim_count vs region

```{r faceted_plot_claim_count_region, echo=FALSE, fig.height=7.5, fig.width=11}
ggplot(combined_tbl) +
    geom_bar(aes(x = claim_count)) +
    scale_y_continuous(labels = comma) +
    facet_wrap(~region, scales = 'free_y') +
    xlab("Claim Count") +
    ylab("Policy Count") +
    ggtitle("Claim Counts by Policy Facetted by Region")
```


## Estimating Large Losses

\

Large losses very random

\

Treat like natural disasters

\

Power-law scaling

---

```{r fit_power_law, echo=FALSE}
logsize <- seq(0, 7, by = 0.1)

powerlaw_tbl <- data_frame(
    logsize = logsize
   ,count   = map_int(logsize, powerlaw_claimsize_count, claimdata_tbl = claim_tbl)
)

ggplot(powerlaw_tbl) +
    geom_line(aes(x = logsize, y = log(count))) +
    xlab('Log of Claim Size') +
    ylab('Log of Claim Count') +
    ggtitle("Power-law Scaling of Claim Sizes")
```

---

```{r plot_power_law_scaling_linefit, echo=FALSE, warning=FALSE}
ggplot(powerlaw_tbl %>% filter(logsize >= 3)) +
    geom_line(aes(x = logsize, y = log(count))) +
    geom_smooth(aes(x = logsize, y = log(count)), method = 'lm', se = TRUE) +
    xlab('Log of Claim Size') +
    ylab('Log of Claim Count') +
    ggtitle("Fitted Scaling for Large Claim Sizes")
```

---

Looks reasonable

---

Slope is scaling factor, $\alpha$

\

$\alpha > 2 \; \implies \mu$ finite

\

$\alpha > 3 \; \implies$ variance finite

---

Definitely want finite $\mu$...

---


```{r calculate_power_law_scaling, echo=TRUE}
pl_tbl <- powerlaw_tbl %>%
    filter(logsize >= 3, count > 0) %>%
    mutate(logcount  = log(count))

pl_lm <- lm(logcount ~ logsize, data = pl_tbl)
```

```{r show_powerlaw_factors, echo=FALSE}
pl_lm %>% tidy %>% (knitr::kable)

pl_scaling <- pl_lm %>%
    tidy %>%
    filter(term == 'logsize') %>%
    pull(estimate)
```

\

Finite $\mu$, non-finite $\text{Var}(x)$


# Proposed Approach

\

$$
\text{Premium} = \text{Claim Rate} \times \text{Claim Size} + \text{Large Claim Charge}
$$
\

Claim rate more predictive power


## Model Attritional Losses

\

Use Poisson / Gamma models for rate / size

\

Estimate of attritional loss cost

\

Each policy has 'fitted' estimate


## Model Catastrophic Losses

\

Use power-law distribution

\

Estimate rate of large losses

\

Use mean loss to calculate flat charge


# Generalized Linear Models

## Basic Concept

\

\begin{eqnarray*}
E(\mathbf{Y})          &=& \mu = g^{-1}(\text{X} \beta) \\
\text{Var}(\mathbf{Y}) &=& V(\mu)
\end{eqnarray*}

\

where

\

\begin{align*}
\mathbf{Y} &= \text{response variable}      \\
\mathbf{X} &= \text{predictor variables}    \\
\beta      &= \text{model coefficients}     \\
g(x)       &= \text{link function}          \\
V(x)       &= \text{variance function}      \\
\end{align*}


---

Combines multiple forms of regression

\

\begin{eqnarray*}
\text{Linear regression}  &\longrightarrow & g(x) = x \\
\\
\text{Poisson regression} &\longrightarrow & g(x) = \log(x) \\
\\
\text{Gamma regression}   &\longrightarrow & g(x) = \frac{1}{x}
\end{eqnarray*}



## Modelling Claim Rate

\

Assume Poisson process

\

Predict per-policy poisson rate

\

Many possible models

---


### Overall Claim Rate

```{r calculate_overall_claim_rate, echo=TRUE}
combined_tbl %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure)) %>%
    pull(claim_rate)
```

---

### Claim Rate by Region

```{r plot_region_claim_rate, echo=FALSE, fig.height=7.5, fig.width=11}
claimrate_region_tbl <- combined_tbl %>%
    group_by(region) %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure))

ggplot(claimrate_region_tbl) +
    geom_point(aes(x = region, y = claim_rate)) +
    expand_limits(y = 0) +
    xlab('Region') +
    ylab('Claim Rate') +
    ggtitle("Plot of Claim Rate by Region")
```

---

### Claim Rate by Driver Age

```{r plot_driver_age_claim_rate, echo=FALSE, fig.height=7.5, fig.width=11}
claimrate_driverage_tbl <- combined_tbl %>%
    group_by(driver_age) %>%
    summarise(claim_rate = sum(claim_count) / sum(exposure))

ggplot(claimrate_driverage_tbl) +
    geom_point(aes(x = driver_age, y = claim_rate)) +
    expand_limits(y = 0) +
    xlab('Driver Age') +
    ylab('Claim Rate') +
    ggtitle("Claim Rate by Driver Age")
```

---

Relationship clearly not linear

\

Could categorise driver age

\

Information loss

\

Use GAM instead

---

HOWEVER

---

Simpler to categorise

\

Will do that here

\

David Leadbetter

---

### Categorise Driver Age

```{r create_cat_driver_age_variables, echo=FALSE, fig.height=7.5}
policy_tbl <- policy_tbl %>%
    mutate(cat_driver_age = cut(driver_age, c(17, 22, 26, 42, 74, Inf)))

ggplot(policy_tbl) +
    geom_bar(aes(x = cat_driver_age)) +
    scale_y_continuous(labels = comma) +
    xlab("Binned Driver Age") +
    ylab("Count") +
    ggtitle("Barplot of Driver Ages after Binning")

policy_tbl <- policy_tbl %>%
    mutate(cat_driver_age = fct_relevel(cat_driver_age, '(26,42]'))
```

---

### First Poisson Model


```{r model_gas, echo=TRUE}
gas_glm <- glm(claim_nb ~ 0 + gas
              ,offset = log(exposure)
              ,data   = policy_tbl
              ,family = poisson)
```

#### Model Diagnostics

```{r model_gas_glance, echo=FALSE}
gas_glm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

#### Model Coefficients

```{r model_gas_tidy, echo=FALSE}
gas_glm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

### Adding Driver Age

```{r model_gas_driverage, echo=TRUE}
expmodel2_glm <- glm(claim_nb ~ gas + cat_driver_age
                    ,offset = log(exposure)
                    ,data   = policy_tbl
                    ,family = poisson)
```

#### Model Diagnostics

```{r model_gas_driverage_glance, echo=FALSE}
expmodel2_glm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

#### Model Coefficients


```{r model_gas_driverage_tidy, echo=FALSE}
expmodel2_glm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

Still just exploration

\

Will decide on final model later


## Modelling Claim Size

\

Claim size always positive

\

Look at distribution of log of claims

---

```{r distribution_log_claim_amount, echo=FALSE}
ggplot(claim_tbl) +
    geom_histogram(aes(x = log(claim_amount)), bins = 50) +
    xlab('Log(Claim Size)') +
    ylab("Probability Density") +
    ggtitle("Histogram of Log of the Claim Size")
```

---

### Linear Model of Log(Claim Size)

```{r construct_claim_reg, echo=FALSE}
claimreg_tbl <- policy_tbl %>%
    inner_join(claim_tbl, by = 'policy_id')
```

```{r model_log_claims, echo=TRUE}
expclaim_lm <- lm(log(claim_amount) ~ gas + power + car_age
                 ,data = claimreg_tbl)
```

#### Model Diagnostics

```{r model_log_claims_glance, echo=FALSE}
expclaim_lm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

#### Model Coefficients

```{r model_log_claims_tidy, echo=FALSE}
expclaim_lm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

Multiple-$R^2$ of 0.0017???

---

What does that even look like?

---

```{r visualise_claim_amount_model, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = expclaim_lm %>% predict(type = 'response') %>% exp)

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount") +
    ggtitle("Plot of Predicted vs Actual Claim Amount")
```

---

### Linear Model of Attritional Log(Claim Size)

```{r model_log_claims_filtered, echo=TRUE}
claimreg_tbl <- claimreg_tbl %>% filter(claim_amount < 25000)

expclaim2_lm <- lm(log(claim_amount) ~ gas + power + car_age
                  ,data = claimreg_tbl)
```

#### Model Diagnostics

```{r model_log_claims_filtered_glance, echo=FALSE}
expclaim2_lm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

#### Model Coefficients

```{r model_log_claims_filtered_tidy, echo=FALSE}
expclaim2_lm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

```{r visualise_claim_amount_model_filtered, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = expclaim2_lm %>% predict(type = 'response') %>% exp)

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount") +
    ggtitle("Plot of Predicted vs Actual Claim Amount for Non-Large Losses")
```

---

Pretty poor

---

Fit a Gamma?

---

### Gamma GLM

```{r fit_claims_gamma, echo=TRUE}
claimgamma_glm <- glm(claim_amount ~ gas + power + car_age
                     ,family = Gamma(link = 'log')
                     ,data   = claimreg_tbl)
```

\


#### Model Diagnostics

```{r claims_gamma_glance, echo=FALSE}
expclaim2_lm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

#### Model Coefficients

```{r claims_gamma_tidy, echo=FALSE}
expclaim2_lm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

```{r visualise_claims_gamma_model, echo=FALSE}
plot_tbl <- claimreg_tbl %>%
    mutate(predict_claim = claimgamma_glm %>% predict(type = 'response'))

ggplot(plot_tbl) +
    geom_point(aes(x = claim_amount, y = predict_claim), alpha = 0.1) +
    expand_limits(y = 0) +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Actual Claim Amount") +
    ylab("Predicted Amount")
```

---

Best to have low expectations


```{r delete_files, echo=FALSE}
rm(expclaim_lm, expclaim2_lm, expmodel2_glm, gas_glm)
```

# Model Assessment

## Assessing Frequency Models

\

Need method of assessment

\

Can use deviance, AIC, BIC

\

Prefer more direct metric

---

Assess model on predicted counts of claims

---

Use model to calculate claim rate

\

Use claim rate to simulate claim counts

\

Match simulated counts to data

\

Observed vs distribution of expected

---

Expect good performance in-sample

\

Want indication for out-of-sample


## Simulation of Claim Counts

\

Split train / validation set

\

Distribution of claim counts for validation

\

Compare to observed counts


---

```{r simulate_claim_counts, echo=FALSE}
usedata_tbl <- policy_tbl %>%
    sample_n(20000)


crossval_tbl <- crossv_mc(usedata_tbl, 12, 0.25, id = 'fold_id') %>%
    mutate(assess    = map2(train, test, create_crossval_assessment)
          ,observed  = map_int(assess, 'observed_count')
          ,predicted = map(assess, 'predicted_count')
          ,cuml_prob = map_dbl(assess, 'cuml_prob')
           )

plot_tbl <- crossval_tbl %>%
    unnest(predicted)

ggplot(plot_tbl) +
    geom_histogram(aes(x = predicted), bins = 25) +
    geom_vline(aes(xintercept = observed), colour = 'red') +
    facet_wrap(~ fold_id, ncol = 4) +
    xlab("Claim Count") +
    ylab("Count") +
    ggtitle("Claim Count Assessment Plot for Claim Frequency")
```

---

Nice for small fold-count

\

Distribution of cumulative probabilities

\

Can extend to full price assessment


## Simulation of Claim Size

\

Lack of predictive power in claim severity

\

Still want to capture uncertainty

\

GLM estimates mean of Gamma

---

$$
X \sim \Gamma(\alpha, \beta)
$$
\


\begin{eqnarray*}
\alpha &=& \text{scale parameter} \\
\beta &=&  \text{rate parameter}
\end{eqnarray*}

---

Want uncertainty $\implies$ simulate from Gamma distribution

\

Need $(\mu, \text{dispersion}) \to (\alpha, \beta)$

\


\begin{eqnarray*}
\alpha &=& \frac{1}{\text{dispersion}} \\
\beta  &=& \frac{\alpha}{\mu}
\end{eqnarray*}


## Assessment Approach

\

Train / validation split

\

Fit model on each split

\

Use uncertainty at multiple levels


---

### Simple Frequency/Severity

\

Predict per policy claim frequency / severity

\

Distribution of predicted vs observed

---

Not much capture of uncertainty

---

### Simulate Claim Counts

\

Simulate claim counts from claim rate

\

Average claim size

\

Multiply to calculate simulated loss cost

---

Claim size very noisy

\

Likely to underestimate variance

---

### Simulate Claim Count and Size

\

Simulate claim counts from claim rate

\

Simulate claim size from prediction

\

Multiply through for loss calculation

---

More involved computation

\

Reasonable estimate of uncertainty / variance




# Building a Premium Quoter

## Data Preparation

\

Remove drivers older than 75 years

\

Remove cars older than 20 years

---

```{r filter_data, echo=FALSE}
quotepolicy_tbl <- policy_tbl %>%
    filter(driver_age <= 75, car_age <= 20)

quoteclaim_tbl <- claim_tbl %>%
    filter(claim_amount < 25000)
```

Total size of dataset after filters: `r quotepolicy_tbl %>% nrow %>% comma`

\

```{r show_filtered_data, echo=FALSE}
quotepolicy_tbl %>% head %>% (knitr::kable)(digits = 2)
```

---

### Split Data

\

Standard Train/Test split

\

Take 100,000 policies for test

\

```{r split_data, echo=FALSE}
aggclaims_tbl <- quoteclaim_tbl %>%
    group_by(policy_id) %>%
    summarise(claim_count = n()
             ,claim_total = sum(claim_amount)
              )

attr_combined_tbl <- quotepolicy_tbl %>%
    left_join(aggclaims_tbl, by = 'policy_id') %>%
    mutate(claim_count = fill_na_values(claim_count) %>% as.integer
          ,claim_total = fill_na_values(claim_total))

testpolicies_tbl  <- attr_combined_tbl %>%
    sample_n(100000, replace = FALSE) %>%
    arrange(policy_id)

trainpolicies_tbl <- attr_combined_tbl %>%
    anti_join(testpolicies_tbl, by = 'policy_id') %>%
    arrange(policy_id)
```

---

```{r show_split_sizes, echo=TRUE}
trainpolicies_tbl %>% nrow
testpolicies_tbl  %>% nrow
```

---

## Model Claim Rate

```{r model_claimrate_driverage, echo=TRUE}
model_01_glm <- glm(claim_nb ~ cat_driver_age
                   ,offset = log(exposure)
                   ,family = poisson
                   ,data   = trainpolicies_tbl)
```

### Model Diagnostics

```{r model_claimrate_01_glance, echo=FALSE}
model_01_glm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

### Model Coefficients

```{r model_claimrate_01_tidy, echo=FALSE}
model_01_glm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

## Final Claim Rate Model

```{r model_claimrate_02, echo=TRUE}
model_02_glm <- glm(claim_nb ~ gas + cat_driver_age + car_age + density +
                               cat_driver_age:gas
                   ,offset = log(exposure)
                   ,family = poisson
                   ,data   = trainpolicies_tbl)
```

### Model Diagnostics

```{r model_claimrate_02_glance, echo=FALSE}
model_02_glm %>%
    glance %>%
    gather('diagnostic', 'value') %>%
    (knitr::kable)(digits = 2)
```

---

### Model Coefficients

```{r model_claimrate_02_tidy, echo=FALSE}
model_02_glm %>% tidy %>% (knitr::kable)(digits = 4)
```

---

## Assess Claim Rate Model

\

Use predictive checks as before

---

```{r assess_claimfrequency_model, echo=FALSE}
assessment_count <- 12

claimfreq_assessment_tbl <- crossv_mc(trainpolicies_tbl
                                     ,assessment_count
                                     ,test = 0.25
                                     ,id = 'fold_id') %>%
    mutate(assess    = map2(train, test, create_claimrate_assessment)
          ,observed  = map_int(assess, 'observed_count')
          ,predicted = map(assess, 'predicted_count')
          ,cuml_prob = map_dbl(assess, 'cuml_prob')
           )

plot_tbl <- claimfreq_assessment_tbl %>%
    unnest(predicted)

ggplot(plot_tbl) +
    geom_histogram(aes(x = predicted), bins = 25) +
    geom_vline(aes(xintercept = observed), colour = 'red') +
    facet_wrap(~ fold_id, ncol = 4) +
    scale_x_continuous(labels = comma) +
    xlab("Claim Count") +
    ylab("Count") +
    ggtitle("Claim Count Assessment Plot for Claim Frequency Model") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

---

What about claim size?

---

Models little use

---

Assume average claim size

\


```{r calculate_mean_claim_size, echo=TRUE}
claim_tbl %>%
    filter(claim_amount <= 25000) %>%
    summarise(mean_amount = mean(claim_amount))
```

\

Use this for claim prediction

```{r create_claimsize_model, echo=FALSE}
modelclaim_tbl <- quoteclaim_tbl %>%
    inner_join(quotepolicy_tbl, by = 'policy_id')

claimsize_glm <- glm(claim_amount ~ cat_driver_age
                    ,family = Gamma(link = 'log')
                    ,data   = modelclaim_tbl)
```


---

## Calculate Large Loss Charge

```{r estimate_largeloss_rate, echo=FALSE}
largeclaim_count <- claim_tbl %>%
    filter(claim_amount >= 25000) %>%
    nrow

largeclaim_prop <- largeclaim_count / (policy_tbl$exposure %>% sum)
```

\

Estimate large-loss rate

\

Large losses per unit exposure


---

Power-law scaling factor

\

$\alpha = `r pl_scaling`$

\

Use to estimate mean of distribution

\

```{r generate_power_law, echo=FALSE}
sample_size <- 1000000

sample_pl <- rpldis(sample_size, xmin = 25000, alpha = pl_scaling)

expected_loss <- sample_pl %>% mean

expected_loss_print <- comma(expected_loss)
```

$\mu = `r expected_loss_print`$

---

Large-loss charge:

\

```{r show_largeclaim_data, echo=TRUE}
expected_loss   %>% round(2) %>% print
largeclaim_prop %>% round(6) %>% print
(largeclaim_prop * expected_loss) %>% round(2) %>% print
```

---


## Create Premium Quoter Function

\

Use higher-order functions

\

Takes policy table, produces price quotes

---

```{r create_premium_quoter_function, echo=FALSE}
premium_quoter <- create_pricing_function(
    claimrate_model_glm = model_02_glm
   ,claimsize_model_glm = claimsize_glm
   ,largeloss_charge    = largeclaim_prop * expected_loss
   ,quote_ratio         = 0.35
)
```


```{r calculate_premium_price, echo=FALSE}
usedata_tbl <- trainpolicies_tbl %>% sample_n(100000)

pricing_tbl <- premium_quoter(usedata_tbl) %>%
    mutate(policy_id = usedata_tbl$policy_id)
```

```{r show_premium_table, echo=FALSE}
pricing_tbl %>%
    select(policy_id, expect_price, largeloss_charge, risk_premium, quote_price) %>%
    arrange(policy_id) %>%
    head(n = 20) %>%
    (knitr::kable)(digits = 2)
```


# Assess the Pricing

\

Do the premia cover losses?

\

Do the premia result in expected profit?

\

Can we test attritional and large claims separately?


---

## Test-Run Assessment Method

\

Simulate claims using poisson model

\

For each claim, simulate claim size

\

Assign loss-cost to each claim

\

Compare paid out losses to collected premia


---

### Assess Training Data

```{r sanity_check_training, echo=FALSE}
data_count <- 100000

usedata_tbl <- trainpolicies_tbl %>% sample_n(data_count)

train_validation_tbl <- usedata_tbl %>%
    mutate(claim_rate   = predict(model_02_glm,  newdata = usedata_tbl, type = 'response')
          ,claim_amount = predict(claimsize_glm, newdata = usedata_tbl, type = 'response')
          ,claim_counts = map(claim_rate, function(l) rpois(1000, l))
          ,claim_costs  = map2(claim_amount, claim_counts, `*`)
           )
```

```{r check_training_data_claim_count, echo=FALSE, fig.height=7.5}
insamp_sim_claim_count <- train_validation_tbl$claim_counts %>% reduce(`+`)
insamp_obs_claim_count <- train_validation_tbl$claim_count %>% sum

claimcount_insample_plot <- ggplot() +
    geom_histogram(aes(x = insamp_sim_claim_count), bins = 50) +
    geom_vline(aes(xintercept = insamp_obs_claim_count), colour = 'red') +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("In-Sample Comparison Plot for Simulated Claim Counts vs Observed"
           ,subtitle = paste0((data_count %>% comma), " Policies Used")
            )

claimcount_insample_plot %>% print
```

---

```{r check_training_data_loss_cost, echo=FALSE}
insamp_sim_loss_amount <- train_validation_tbl$claim_costs %>% reduce(`+`)
insamp_obs_loss_amount <- train_validation_tbl$claim_total %>% reduce(`+`)

losscost_insample_plot <- ggplot() +
    geom_histogram(aes(x = insamp_sim_loss_amount), bins = 50) +
    geom_vline(aes(xintercept = insamp_obs_loss_amount), colour = 'red') +
    scale_x_continuous(labels = dollar) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("In-Sample Comparison Plot for Simulated Loss Costs vs Observed"
           ,subtitle = paste0((data_count %>% comma), " Policies Used")
            )

losscost_insample_plot %>% print
```

---

### Assess Out-of-Sample Data

```{r model_validation_oos, echo=FALSE}
data_count <- 50000

valid_tbl <- trainpolicies_tbl %>%
    anti_join(usedata_tbl, by = 'policy_id') %>%
    sample_n(data_count)

oos_validation_tbl <- valid_tbl %>%
    mutate(claim_rate   = predict(model_02_glm,  newdata = valid_tbl, type = 'response')
          ,claim_amount = predict(claimsize_glm, newdata = valid_tbl, type = 'response')
          ,claim_counts = map(claim_rate, function(l) rpois(1000, l))
          ,claim_costs  = map2(claim_amount, claim_counts, `*`)
           )
```

```{r check_oos_data_claim_count, echo=FALSE, fig.height=7.5}
oos_sim_claim_count <- oos_validation_tbl$claim_counts %>% reduce(`+`)
oos_obs_claim_count <- oos_validation_tbl$claim_count %>% sum

claimcount_outsample_plot <- ggplot() +
    geom_histogram(aes(x = oos_sim_claim_count), bins = 50) +
    geom_vline(aes(xintercept = oos_obs_claim_count), colour = 'red') +
    scale_x_continuous(labels = comma) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("Out-of-Sample Comparison Plot for Simulated Claim Counts vs Observed"
           ,subtitle = paste0((data_count %>% comma), " Policies Used")
            )

claimcount_outsample_plot %>% print
```

---

```{r check_oos_data_loss_cost, echo=FALSE}
oos_sim_loss_amount <- oos_validation_tbl$claim_costs %>% reduce(`+`)
oos_obs_loss_amount <- oos_validation_tbl$claim_total %>% reduce(`+`)

losscost_outsample_plot <- ggplot() +
    geom_histogram(aes(x = oos_sim_loss_amount), bins = 50) +
    geom_vline(aes(xintercept = oos_obs_loss_amount), colour = 'red') +
    scale_x_continuous(labels = dollar) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("Out-of-Sample Comparison Plot for Simulated Loss Costs vs Observed"
           ,subtitle = paste0((data_count %>% comma), " Policies Used")
            )

losscost_outsample_plot %>% print
```


## Adding Claim Size Variation

```{r simulate_claim_size_insample, echo=FALSE, fig.height=7}
calculate_claim_sizes <- function(claim_list, shape, rate) {
    total_claims <- claim_list %>% sum
    
    claim_amounts <- rgamma(total_claims, shape = shape, rate = rate)
    
    claim_amount_cumsum <- c(0, claim_amounts %>% cumsum)
    
    claim_idx <- claim_list %>% cumsum
    
    claim_cumsum <- c(0, claim_amount_cumsum[claim_idx + 1])
    
    claim_sizes <- claim_cumsum %>% diff

    return(claim_sizes)
}

train_claimsize_validation_tbl <- usedata_tbl %>%
    mutate(claim_rate       = predict(model_02_glm,  newdata = usedata_tbl, type = 'response')
          ,claim_counts     = map(claim_rate, function(l) rpois(1000, l))
          ,claim_size_mu    = predict(claimsize_glm, newdata = usedata_tbl, type = 'response')
          ,claim_size_shape = MASS::gamma.shape(claimsize_glm)$alpha
          ,claim_size_rate  = claim_size_shape / claim_size_mu
          ,claim_costs      = map(claim_counts, calculate_claim_sizes, shape = claim_size_shape, rate = claim_size_rate)
           )
```

```{r check_simulate_claim_size_insample, echo=FALSE, fig.height=7.5}
insamp_varsize_sim_loss_amount <- train_claimsize_validation_tbl$claim_costs %>% reduce(`+`)
insamp_varsize_obs_loss_amount <- train_claimsize_validation_tbl$claim_total %>% reduce(`+`)

losscost_varsize_insample_plot <- ggplot() +
    geom_histogram(aes(x = insamp_varsize_sim_loss_amount), bins = 50) +
    geom_vline(aes(xintercept = insamp_varsize_obs_loss_amount), colour = 'red') +
    scale_x_continuous(labels = dollar) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("In-Sample Comparison Plot for Random Claim Size Simulated Loss Costs vs Observed"
           ,subtitle = paste0((usedata_tbl %>% nrow %>% comma), " Policies Used")
            )

losscost_varsize_insample_plot %>% print
```

---

```{r check_simulate_claim_size_oos, echo=FALSE}
oos_claimsize_validation_tbl <- valid_tbl %>%
    mutate(claim_rate       = predict(model_02_glm,  newdata = valid_tbl, type = 'response')
          ,claim_size_mu    = predict(claimsize_glm, newdata = valid_tbl, type = 'response')
          ,claim_size_shape = MASS::gamma.shape(claimsize_glm)$alpha
          ,claim_size_rate  = claim_size_shape / claim_size_mu
          ,claim_counts     = map(claim_rate, function(l) rpois(1000, l))
          ,claim_costs      = map(claim_counts, calculate_claim_sizes, shape = claim_size_shape, rate = claim_size_rate)
           )

insamp_varsize_sim_loss_amount <- oos_claimsize_validation_tbl$claim_costs %>% reduce(`+`)
insamp_varsize_obs_loss_amount <- oos_claimsize_validation_tbl$claim_total %>% reduce(`+`)

losscost_varsize_outsample_plot <- ggplot() +
    geom_histogram(aes(x = insamp_varsize_sim_loss_amount), bins = 50) +
    geom_vline(aes(xintercept = insamp_varsize_obs_loss_amount), colour = 'red') +
    scale_x_continuous(labels = dollar) +
    scale_y_continuous(labels = comma) +
    xlab("Claims Paid") +
    ylab("Count") +
    ggtitle("Out-of-Sample Comparison Plot for Random Claim Size Simulated Loss Costs vs Observed"
           ,subtitle = paste0((valid_tbl %>% nrow %>% comma), " Policies Used")
            )

losscost_varsize_outsample_plot %>% print
```

---

```{r show_all_plot, echo=FALSE}
plot_grid(losscost_insample_plot +
              ggtitle("In-Sample, Fixed Claim Size"
                     ,subtitle = losscost_insample_plot$labels$subtitle)
         ,losscost_outsample_plot +
             ggtitle("Out-of-Sample, Fixed Claim Size"
                     ,subtitle = losscost_outsample_plot$labels$subtitle)
         ,losscost_varsize_insample_plot  +
             ggtitle("In-Sample, Variable Claim Size"
                     ,subtitle = losscost_varsize_insample_plot$labels$subtitle)
         ,losscost_varsize_outsample_plot +
             ggtitle("Out-of-Sample, Variable Claim Size"
                     ,subtitle = losscost_varsize_outsample_plot$labels$subtitle)
         ,ncol = 2
          )

```





# Future Steps

## Problems and Shortcomings

\

GLMs simplistic, may need overdispersed models

\

Need more validation / testing

\

Claims prediction needs work


## Future Improvements

\

Perform more thorough testing

\

Use Bayesian version - `stan_glm`

\

Improve linear models - GAMs


## Further Resources

\

https://github.com/kaybenleroll/carinsurance_pricing

\

http://ijlyttle.github.io/isugg_purrr/presentation.html#(1)

\





## Questions?

\

Email: mickcooney@gmail.com

\

GitHub: https://github.com/kaybenleroll/dublin_r_workshops


