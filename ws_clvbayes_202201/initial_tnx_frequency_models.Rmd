---
title: "Building Transactional Frequency Models"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    code_folding: hide
    fig_caption: TRUE

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(cmdstanr)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)


source("lib_utils.R")

conflict_lst <- resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```

In this workbook we investigate different ways to model the transaction
frequency of individual customers, with a view to expanding this approach into
a more traditional P/NBD model.

```{r load_transaction_data, echo=TRUE}
customer_basic_transactions_tbl <- read_rds("data/customer_basic_transactions_tbl.rds")
customer_basic_transactions_tbl %>% glimpse()

customer_basic_simparams_tbl <- read_rds("data/customer_basic_simparams_tbl.rds")
customer_basic_simparams_tbl %>% glimpse()
```



```{r construct_frequency_modelling_data, echo=TRUE}
basic_freqmodelling_tbl <- customer_basic_transactions_tbl %>%
  group_by(customer_id) %>%
  summarise(
    .groups = "drop",
    
    tnx_count = n(),
    tnx_time  = difftime(max(tnx_timestamp), min(tnx_timestamp), units = "weeks") %>% as.numeric()
    )

basic_freqmodelling_tbl %>% glimpse()
```

We also want to construct the a version of the data where only the customers
with multiple transactions remain in the dataset.

```{r construct_transaction_clvdata, echo=TRUE}
customer_basic_tnxsummary_tbl <- basic_freqmodelling_tbl %>%
  filter(tnx_count > 1) %>%
  mutate(
    x = tnx_count - 1,
    t = tnx_time
    )

customer_basic_tnxsummary_tbl %>% glimpse()
```


# Construct Fixed Hyper-prior Frequency Model



```{r construct_nonhier_freqmodel, echo=TRUE}
nonhier_freq_stanmodel <- cmdstan_model(
  "stan_code/clv_freqmodel_nonhier.stan",
  include_paths = "stan_code/",
  pedantic      =  TRUE,
  dir           = "stan_models/"
  )

stan_data_lst <- customer_basic_tnxsummary_tbl %>%
  compose_data(
    r     =  1,
    alpha =  3
    )

nonhier_freq_stanfit <- nonhier_freq_stanmodel$sample(
  data          =  stan_data_lst,
  chains        =              4,
  iter_warmup   =           1000,
  iter_sampling =           1000,
  seed          =            421
  )
```

```{r nonhier_freq_calculate_diagnostics_output_files, echo=TRUE}
nonhier_freq_stanfit$cmdstan_diagnose()

nonhier_freq_stanfit$save_output_files(
  dir      = "stan_models",
  basename = "nonhier_freq"
)
```


## Perform Customer Frequency Validation

```{r perform_nonhier_customer_freq_validation, echo=TRUE}
nonhier_post_freq_tbl <- nonhier_freq_stanfit$draws() %>%
  recover_types(customer_basic_tnxsummary_tbl) %>%
  spread_draws(lambda[customer_id]) %>%
  ungroup()

nonhier_post_freq_tbl %>% glimpse()
```

We now use the posterior distribution of each parameter to construct an ECDF
function that we use to calculate the q-value of the parameter

```{r calculate_posterior_qvalues, echo=TRUE}
nonhier_qval_validation_tbl <- nonhier_post_freq_tbl %>%
  group_by(customer_id) %>%
  summarise(
    .groups = "drop",
    
    lambda_vals = list(lambda)
    ) %>%
  inner_join(customer_basic_simparams_tbl, by = "customer_id") %>%
  mutate(
    lambda_qval = map2_dbl(lambda_vals, customer_lambda, ~ ecdf(.x)(.y))
    )

nonhier_qval_validation_tbl %>% glimpse()
```

```{r}
ggplot(nonhier_qval_validation_tbl) +
  geom_histogram(aes(x = lambda_qval), bins = 50)
```


# Construct Hierarchical Frequency Model

```{r construct_hier_freqmodel, echo=TRUE}
hier_freq_stanmodel <- cmdstan_model(
  "stan_code/clv_freqmodel_hier.stan",
  include_paths = "stan_code/",
  pedantic      =  TRUE,
  dir           = "stan_models/"
  )

stan_data_lst <- customer_basic_tnxsummary_tbl %>%
  compose_data()

hier_freq_stanfit <- hier_freq_stanmodel$sample(
  data          =  stan_data_lst,
  chains        =              4,
  iter_warmup   =           1000,
  iter_sampling =           1000,
  seed          =            422
  )

hier_freq_stanfit$summary(
  c("lb_mean", "lb_cov", "r", "alpha")
  )
```

```{r hier_freq_calculate_diagnostics_output_files, echo=TRUE}
hier_freq_stanfit$cmdstan_diagnose()

hier_freq_stanfit$save_output_files(
  dir      = "stan_models",
  basename = "hier_freq"
)
```







# Construct brms Version of Frequency Model

```{r build_brms_freqmodel, echo=TRUE, eval=FALSE}
freqmodel_brmsfit <- brm(
  bf(tnx_count ~ (1 | customer_id)),
  prior  = c(set_prior("gamma(1, 3)", class = "Intercept")),
  data   = freqmodelling_tbl,
  family = poisson(),
  chains = 4,
  iter   = 2000,
  seed   = 42
  )
```








# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
options(width = 120L)
sessioninfo::session_info()
options(width = 80L)
```
