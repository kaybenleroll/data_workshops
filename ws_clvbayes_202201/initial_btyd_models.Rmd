---
title: "Using Buy-Till-You-Die (BTYD) Models the Online Retail Dataset"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: yes
    css: styles.css

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(CLVTools)
library(tidyquant)
library(rsample)
library(MASS)
library(fitdistrplus)
library(rstan)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)


source("lib_utils.R")

resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "MASS",
    "fitdistrplus")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```


# Load Data

We first want to load our datasets and perform some basic manipulation similar
to those done for the association rules mining.

```{r load_transaction_data, echo=TRUE}
tnx_data_tbl <- read_rds("data/retail_data_cleaned_tbl.rds")

tnx_data_tbl %>% glimpse()
```


We model the purchase data first, then combine this to create an individual
customer/invoice pairing with the total amount spent as an additional column.

```{r prepare_purchase_data, echo=TRUE}
tnx_purchase_tbl <- tnx_data_tbl %>%
  filter(
    quantity > 0,
    price > 0,
    exclude == FALSE
    ) %>%
  drop_na(customer_id) %>%
  select(
    invoice_date, invoice_id, stock_code, customer_id, description,
    quantity, price, stock_value
    )

tnx_purchase_tbl %>% glimpse()
```

Use of BTYD models assumes a total spend over a period of day and those
differences between the times. This is calculated internally by the various
BTYD routines so we keep just the per-invoice spend.

```{r calculate_customer_daily_spend, echo=TRUE}
daily_spend_invoice_tbl <- tnx_purchase_tbl %>%
  drop_na(customer_id) %>%
  group_by(invoice_date, customer_id, invoice_id) %>%
  summarise(
    .groups = "drop",
    
    invoice_spend = sum(stock_value)
    )

daily_spend_invoice_tbl %>% glimpse()


daily_spend_tbl <- daily_spend_invoice_tbl %>%
  group_by(invoice_date, customer_id) %>%
  summarise(
    .groups = "drop",
    
    total_spend = sum(invoice_spend),
    tnx_count   = n()
    )

daily_spend_tbl %>% glimpse()
```


Finally, we want to set a date to make the end of the "fitting" data, which
will be used in the various estimation routines to fit parameters of our models.

```{r set_training_data_date, echo=TRUE}
training_data_date <- as.Date("2011-03-31")
```


# Background Theory

Before we start working on fitting and using the various Buy-Till-You-Die
models, we first need to discuss the basic underlying theory and model.

In this model, we assume a customer becomes 'alive' to the business at the
first purchase and then makes purchases stochastically but at a steady-rate
for a period of time, and then 'dies' - i.e. becomes inactive to the business -
hence the use of "Buy-Till-You-Die".

Thus, at a high level these models decompose into modelling the transaction
events using distributions such as the Poisson or Negative Binomial, and then
modelling the 'dropout' process using some other method.

A number of BTYD models exist and for this workshop we will focus on the
BG/NBD model - the Beta-Geometric Negative Binomial Distribution model (though
we will discuss the P/NBD model also).

These models require only two pieces of information about each customer's
purchasing history: the "recency" (when the last transaction occurred) and
"frequency" (the count of transactions made by that customer in a specified
time period).

The notation used to represent this information is

$$
X = (x, t_x, T),
$$
where $x$ is the number of transactions observed in the time period $T$ and
$t_x$ was the time of the last transaction.

From this summary data we can fit both P/NBD and BG/NBD models.


## Beta-Geometric/Negative-Binomial Distribution (BG/NBD) Model

This model relies on a number of base assumptions:

  1. While active, the number of transactions made by a customer follows a
  Poisson process with transaction rate $\lambda$.
  1. Heterogeneity in $\lambda$ follows a Gamma distribution
  $\Gamma(\lambda \, | \, \alpha, r)$ with parameters shape $r$ and rate
  $\alpha$. 
  1. After any transaction, a customer becomes inactive with probability $p$.
  1. Heterogeneity in $p$ follows a Beta distribution $B(p \, | \, a, b)$ with
  shape parameters $a$ and $b$.
  1. The transaction rate $\lambda$ and the dropout probability $p$ vary
  independently across customers.


Note that it follows from the above assumptions that the probability of a
customer being 'alive' after any transaction is given by the Geometric
distribution, and hence the Beta-Geometric in the name.


## Pareto/Negative-Binomial Distribution (P/NBD) Model

Similar to the BG/NBD model, the P/NBD model relies on five assumptions:

  1. While active, the number of transactions made by a customer follows a
  Poisson process with transaction rate $\lambda$.
  1. Heterogeneity in $\lambda$ follows a Gamma distribution
  $\Gamma(\lambda \, | \, \alpha, r)$ with shape $r$ and rate $\alpha$. 
  1. Each customer has an unobserved 'lifetime' of length $\tau$. This point at
  which the customer becomes inactive is distributed as an exponential with
  dropout rate $\mu$.
  1. Heterogeneity in dropout rates across customers follows a Gamma
  distribution $\Gamma(\mu \, | \, s, \beta)$ with shape parameter $s$ and
  rate parameter $\beta$.
  1. The transaction rate $\lambda$ and the dropout rate $\mu$ vary
  independently across customers.


## Gamma/Gamma Spending Model

The final piece of this approach is to construct a spending model for the
transactions. Similar to transaction rates, spending patterns are often
skewed, so a Gamma distribution is used.

For the Gamma/Gamma model, we use the following assumptions:

  1. Each transaction amount, $v_i$, is distributed according to a Gamma
  distribution $\Gamma(v_i \, | \, p, \nu)$ with shape parameter $p$ and
  rate parameter $\nu$.
  2. Heterogeneity in $p$ follows a Gamma distribution
  $\Gamma(p \, | \, q, \gamma)$






# Construct Stan Models

## Data Preparation

We now need to prepare the data in the formats required to fit these models.

For the purposes of the P/NBD model, we only require three summary statistics
for each customer. In each case, the units of time are calculated relative to
when the customer appears on the system - this allows us to account for the
fact that a customer *born* more recently has had less time to make purchases.

Thus, each customers transaction data is summaries by a triplet of three values
$(x, t_x, t_{\text{cal}})$


$$
\begin{eqnarray}
x              &=& \text{ count of transactions in the data}, \\
t_x            &=& \text{ time of the most recently made transaction}, \\
t_{\text{cal}} &=& \text{ time since first transaction made by the customer}
\end{eqnarray}
$$

```{r construct_clvdata, echo=TRUE}
customer_clvdata_tbl <- daily_spend_tbl %>%
  left_join(customer_firstdate_tbl, by = "customer_id") %>%
  filter(first_tnx_date <= training_data_date) %>%
  clvdata(
    date.format = "%Y-%m-%d",
    time.unit = "weeks",
    estimation.split = training_data_date,
    name.id          = "customer_id",
    name.date        = "invoice_date",
    name.price       = "total_spend"
    )

customer_clvdata_tbl %>% glimpse()
```

Now that we have constructed the `clvdata` structure, we can use this input
to construct the summary statistics required for our models. This data is
performed by internal routines in `CLVTools`, so we use those directly.

```{r construct_pnbd_input_data, echo=TRUE}
customer_pnbd_cbs_tbl <- customer_clvdata_tbl %>%
  (CLVTools:::pnbd_cbs)()

pnbd_data_lst <- list(
  N         = customer_pnbd_cbs_tbl %>% nrow(),
  n         = customer_pnbd_cbs_tbl %>% nrow(),
  
  T         = customer_pnbd_cbs_tbl %>% pull(T.cal),

  recency   = customer_pnbd_cbs_tbl %>% pull(t.x),
  t         = customer_pnbd_cbs_tbl %>% pull(t.x),
  
  frequency = customer_pnbd_cbs_tbl %>% pull(x),
  k         = customer_pnbd_cbs_tbl %>% pull(x)
  )

pnbd_data_lst %>% glimpse()
```



## Construct Fixed Priors Model

```{r construct_fixed_stan_model, echo=TRUE}
pnbd_fixed_stanmodel <- stan_model(
  "stan_files/clv_pnbd_fixed.stan",
  model_name = "pnbd_fixed_model",
  verbose    = TRUE
  )
```


```{r fit_fixed_stan_model, echo=TRUE, cache=TRUE}
stan_data_lst <- compose_data(
  pnbd_data_lst,
  
  etau_shape   =  1,
  etau_rate    = 10,
  
  lambda_shape =  1,
  lambda_rate  = 10
  )


pnbd_fixed_stanfit <- sampling(
  pnbd_fixed_stanmodel,
  data   = stan_data_lst,
  chains = 4,
  iter   = 1000,
  seed   = 42
  )

pnbd_fixed_stanfit %>% summary()
```


```{r extract_fixed_stanmodel_params, echo=TRUE}
pnbd_fixed_postparams_tbl <- pnbd_fixed_stanfit %>%
  tidy_draws() %>%
  pivot_longer(
    !c(.chain, .iteration, .draw),
    names_to  = "parameter",
    values_to = "value"
    )

pnbd_fixed_postparams_tbl %>% glimpse()
```


## Construct Basic Priors Model

```{r construct_priors_stan_model, echo=TRUE}
pnbd_priors_stanmodel <- stan_model(
  "stan_files/clv_pnbd_priormean.stan",
  model_name = "pnbd_priors_model",
  verbose    = TRUE
  )
```


```{r fit_priors_stan_model, echo=TRUE}
stan_data_lst <- compose_data(
  pnbd_data_lst,
  
  etau_shape   = 1,
  etau_rate    = 1
  )


# pnbd_priors_stanfit <- sampling(
#   pnbd_priors_stanmodel,
#   data   = stan_data_lst,
#   chains = 4,
#   iter   = 1000,
#   seed   = 42
#   )
# 
# pnbd_priors_stanfit %>% summary()
```


```{r plot_priors_stanmodel_params, echo=TRUE}
# pnbd_priors_postparams_tbl <- pnbd_priors_stanfit %>%
#   tidy_draws() %>%
#   pivot_longer(
#     !c(.chain, .iteration, .draw),
#     names_to  = "parameter",
#     values_to = "value"
#     )
# 
# pnbd_priors_postparams_tbl %>% glimpse()
```




# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
sessioninfo::session_info()
```
