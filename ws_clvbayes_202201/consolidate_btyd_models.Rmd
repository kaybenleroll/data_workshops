---
title: "Consolidate BTYD Models"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    code_folding: hide
    fig_caption: TRUE

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(cmdstanr)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)


source("lib_utils.R")
source("lib_btyd.R")


conflict_lst <- resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "MASS",
    "fitdistrplus")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```







# Load Transactional Datasets

We first want to load the real-world transactional dataset.


## Load Pre-processed Transactional Data


```{r load_customer_cohort_data, echo=TRUE}
customer_cohortdata_tbl <- read_rds("data/customer_cohort_tbl.rds")
customer_cohortdata_tbl %>% glimpse()
```

We also want to load the raw transaction data as we want to transform the data
into a form we now use.

```{r load_transactional_data, echo=TRUE}
retail_transaction_data_tbl <- read_rds("data/retail_data_cleaned_tbl.rds")
retail_transaction_data_tbl %>% glimpse()
```

We need to aggregate this data up into a form to match our synthetic data, so
we aggregate transactions by `invoice_id`.


```{r aggregate_total_transaction_spend_data, echo=TRUE}
customer_transactions_tbl <- retail_transaction_data_tbl %>%
  drop_na(customer_id) %>%
  filter(exclude = TRUE) %>%
  group_by(tnx_timestamp = invoice_dttm, customer_id, invoice_id) %>%
  summarise(
    .groups = "drop",
    
    total_spend = sum(stock_value)
    ) %>%
  filter(total_spend > 0) %>%
  arrange(tnx_timestamp, customer_id)

customer_transactions_tbl %>% glimpse()
```


We re-produce the visualisation of the transaction times we used in previous
workbooks.

```{r plot_customer_transaction_times, echo=TRUE}
plot_tbl <- customer_transactions_tbl %>%
  group_nest(customer_id, .key = "cust_data") %>%
  filter(map_int(cust_data, nrow) > 3) %>%
  slice_sample(n = 30) %>%
  unnest(cust_data)

ggplot(plot_tbl, aes(x = tnx_timestamp, y = customer_id)) +
  geom_line() +
  geom_point() +
  labs(
      x = "Date",
      y = "Customer ID",
      title = "Visualisation of Customer Transaction Times"
    ) +
  theme(axis.text.y = element_text(size = 10))
```


# Fit the Fixed Prior P/NBD Model


```{r setup_workbook_parameters, echo=TRUE}
stan_modeldir <- "stan_models"
stan_codedir  <-   "stan_code"
```


We first need to construct our fitted dataset from this external data.



In terms of choosing a cut-off point, we will consider all transactions up to
and including March 31, 2011.

```{r construct_fitting_dataset, echo=TRUE}
btyd_fitdata_tbl <- customer_transactions_tbl %>%
  calculate_transaction_cbs_data(last_date = as.POSIXct("2011-01-01"))

btyd_fitdata_tbl %>% glimpse()
```

We also want to construct some summary statistics for the data after that.

```{r construct_validation_summary_statistics, echo=TRUE}
btyd_obs_stats_tbl <- customer_transactions_tbl %>%
  filter(
    tnx_timestamp >= as.POSIXct("2011-01-01")
    ) %>%
  group_by(customer_id) %>%
  summarise(
    .groups = "drop",
    
    tnx_count = n(),
    first_tnx = min(tnx_timestamp),
    last_tnx  = max(tnx_timestamp)
    )

btyd_obs_stats_tbl %>% glimpse()
```


We now compile this model using `CmdStanR`.

```{r compile_pnbd_consol_fixed_stanmodel, echo=TRUE, results="hide"}
pnbd_consol_fixed_stanmodel <- cmdstan_model(
  "stan_code/pnbd_fixed.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


## Fit the Model

We then use this compiled model with our data to produce a fit of the data.

```{r fit_pnbd_consol_fixed_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "pnbd_consol_fixed"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- btyd_fitdata_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn = 0.25,
    lambda_cv = 1.00,
    
    mu_mn     = 0.05,
    mu_cv     = 1.00,
    )

pnbd_consol_fixed_stanfit <- pnbd_consol_fixed_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          500,
  iter_sampling   =                          500,
  seed            =                         4201,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

pnbd_consol_fixed_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_pnbd_consol_fixed_hmc_diagnostics, echo=TRUE, cache=TRUE}
pnbd_consol_fixed_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_consol_fixed_traceplots, echo=TRUE}
parameter_subset <- c(
  "lambda[1]", "lambda[2]", "lambda[3]", "lambda[4]",
  "mu[1]",     "mu[2]",     "mu[3]",     "mu[4]"
  )

pnbd_consol_fixed_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = parameter_subset) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and Mu Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```


A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_pnbd_consol_fixed_parameter_rhat, echo=TRUE}
pnbd_consol_fixed_stanfit %>%
  rhat(pars = c("lambda", "mu")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_pnbd_consol_fixed_parameter_neffratio, echo=TRUE}
pnbd_consol_fixed_stanfit %>%
  neff_ratio(pars = c("lambda", "mu")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_pnbd_consol_fixed_parameter_acf, echo=TRUE}
pnbd_consol_fixed_stanfit$draws() %>%
  mcmc_acf(pars = parameter_subset) +
    ggtitle("Autocorrelation Plot of Sample Values")
```


## Validate the Fixed Prior Model

```{r construct_pnbd_consol_fixed_validation_data, echo=TRUE}
run_chunk <- function(sim_file, param_tbl)
  run_pnbd_simulations_chunk(
    sim_file, param_tbl,
    start_dttm = as.POSIXct("2011-01-01"),
    end_dttm   = as.POSIXct("2011-12-10")
    )


pnbd_consol_fixed_valid_lst <- construct_model_validation_data(
    btyd_stanfit       = pnbd_consol_fixed_stanfit,
    btyd_fitdata_tbl   = btyd_fitdata_tbl,
    btyd_obs_stats_tbl = btyd_obs_stats_tbl,
    precompute_dir     = "precompute/pnbd_consol_fixed",
    precompute_key     = "sims_pnbd_consol_fixed",
    run_chunk_func     = run_chunk
    )

pnbd_consol_fixed_valid_lst %>% glimpse(max.level = 1)
```

Having ran the simulations, we now want to check the outputs against the
observed data.

```{r pnbd_consol_fixed_valid_lst_validation_plots, echo=TRUE}
pnbd_consol_fixed_valid_lst$valid_custcount_plot %>% print()

pnbd_consol_fixed_valid_lst$valid_tnxcount_plot  %>% print()
```


## Write to Disk

```{r write_files_to_disk, echo=TRUE}
pnbd_consol_fixed_valid_lst %>% write_rds("data/pnbd_consol_fixed_valid_lst.rds")
```



# Fit the Hierarchical Lambda-Mean P/NBD Model


```{r display_pnbd_consol_lambmn_model_stancode, echo=FALSE}
read_lines("stan_code/pnbd_hierlambdamn.stan") %>% cat(sep = "\n")
```

We now compile this model using `CmdStanR`.

```{r compile_pnbd_consol_lambmn_stanmodel, echo=TRUE, results="hide"}
pnbd_consol_lambmn_stanmodel <- cmdstan_model(
  "stan_code/pnbd_hierlambdamn.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


## Fit the Model

We then use this compiled model with our data to produce a fit of the data.

```{r fit_pnbd_consol_lambmn_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "pnbd_consol_lambmn"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- btyd_fitdata_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn_p1 = log(0.25) - 0.5 * (1.0)^2,
    lambda_mn_p2 = 1,
    
    lambda_cv = 1.00,
    
    mu_mn     = 0.05,
    mu_cv     = 0.60,
    )

pnbd_consol_lambmn_stanfit <- pnbd_consol_lambmn_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          500,
  iter_sampling   =                          500,
  seed            =                         4202,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

pnbd_consol_lambmn_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_pnbd_consol_lambmn_hmc_diagnostics, echo=TRUE, cache=TRUE}
pnbd_consol_lambmn_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_consol_lambmn_traceplots, echo=TRUE}
pnbd_consol_lambmn_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = c("lambda_mn", "alpha", "lambda[1]", "lambda[2]", "mu[1]", "mu[2]")) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and Mu Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```


A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_pnbd_consol_lambmn_parameter_rhat, echo=TRUE}
pnbd_consol_lambmn_stanfit %>%
  rhat(pars = c("lambda_mn", "lambda", "mu")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_pnbd_consol_lambmn_parameter_neffratio, echo=TRUE}
pnbd_consol_lambmn_stanfit %>%
  neff_ratio(pars = c("lambda_mn", "lambda", "mu")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_pnbd_consol_lambmn_parameter_acf, echo=TRUE}
pnbd_consol_lambmn_stanfit$draws() %>%
  mcmc_acf(pars = c("lambda_mn", "alpha", "lambda[1]", "lambda[2]", "mu[1]", "mu[2]")) +
    ggtitle("Autocorrelation Plot of Sample Values")
```


## Validate the Lambda-Mean Model

```{r construct_pnbd_consol_lambmn_validation_data, echo=TRUE}
run_chunk <- function(sim_file, param_tbl)
  run_pnbd_simulations_chunk(
    sim_file, param_tbl,
    start_dttm = as.POSIXct("2011-01-01"),
    end_dttm   = as.POSIXct("2011-12-10")
    )


pnbd_consol_lambmn_valid_lst <- construct_model_validation_data(
    btyd_stanfit       = pnbd_consol_lambmn_stanfit,
    btyd_fitdata_tbl   = btyd_fitdata_tbl,
    btyd_obs_stats_tbl = btyd_obs_stats_tbl,
    precompute_dir     = "precompute/pnbd_consol_lambmn",
    precompute_key     = "sims_pnbd_consol_lambmn",
    run_chunk_func     = run_chunk
    )

pnbd_consol_lambmn_valid_lst %>% glimpse(max.level = 1)
```

Having ran the simulations, we now want to check the outputs against the
observed data.

```{r pnbd_consol_lambmn_valid_lst_validation_plots, echo=TRUE}
pnbd_consol_lambmn_valid_lst$valid_custcount_plot %>% print()

pnbd_consol_lambmn_valid_lst$valid_tnxcount_plot  %>% print()
```


# Fit the Fixed Prior BG/NBD Model

We now want to fit our BG/NBD model with fixed priors.


```{r display_bgnbd_fixed_model_stancode, echo=FALSE}
read_lines("stan_code/bgnbd_fixed.stan") %>% cat(sep = "\n")
```

We now compile this model using `CmdStanR`.

```{r compile_bgnbd_fixed_stanmodel, echo=TRUE, results="hide"}
bgnbd_fixed_stanmodel <- cmdstan_model(
  "stan_code/bgnbd_fixed.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


## Fit the Model

We then use this compiled model with our data to produce a fit of the data.

```{r fit_bgnbd_fixed_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "bgnbd_consol_fixed"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- btyd_fitdata_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn = 0.25,
    lambda_cv = 1.00,
    
    p_mn      =  0.10,
    p_k       =  2.00,
    )

bgnbd_fixed_stanfit <- bgnbd_fixed_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          500,
  iter_sampling   =                          500,
  seed            =                         4203,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

bgnbd_fixed_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_bgnbd_fixed_hmc_diagnostics, echo=TRUE, cache=TRUE}
bgnbd_fixed_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_bgnbd_fixed_traceplots, echo=TRUE}
sample_params <- c(
  "lambda[1]", "lambda[2]", "lambda[3]", "lambda[4]", "lambda[5]", "lambda[6]",
  "p[1]",      "p[2]",      "p[3]",      "p[4]",      "p[5]",      "p[6]"
  )

bgnbd_fixed_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = sample_params) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and p Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```


A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_bgnbd_fixed_parameter_rhat, echo=TRUE}
bgnbd_fixed_stanfit %>%
  rhat(pars = c("lambda", "p")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_bgnbd_fixed_parameter_neffratio, echo=TRUE}
bgnbd_fixed_stanfit %>%
  neff_ratio(pars = c("lambda", "p")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_bgnbd_fixed_parameter_acf, echo=TRUE}
bgnbd_fixed_stanfit$draws() %>%
  mcmc_acf(pars = sample_params) +
    ggtitle("Autocorrelation Plot of Sample Values")
```


## Validate the Fixed Prior BG/NBD Model


```{r construct_bgnbd_consol_fixed_validation_data, echo=TRUE}
run_chunk <- function(sim_file, param_tbl)
  run_bgnbd_simulations_chunk(
    sim_file, param_tbl,
    start_dttm = as.POSIXct("2011-01-01"),
    end_dttm   = as.POSIXct("2011-12-10")
    )


bgnbd_consol_fixed_valid_lst <- construct_model_validation_data(
    btyd_stanfit       = bgnbd_consol_fixed_stanfit,
    btyd_fitdata_tbl   = btyd_fitdata_tbl,
    btyd_obs_stats_tbl = btyd_obs_stats_tbl,
    precompute_dir     = "precompute/bgnbd_consol_fixed",
    precompute_key     = "sims_bgnbd_consol_fixed",
    run_chunk_func     = run_chunk
    )

bgnbd_consol_fixed_valid_lst %>% glimpse(max.level = 1)
```

Having ran the simulations, we now want to check the outputs against the
observed data.

```{r bgnbd_consol_fixed_valid_lst_validation_plots, echo=TRUE}
bgnbd_consol_fixed_valid_lst$valid_custcount_plot %>% print()

bgnbd_consol_fixed_valid_lst$valid_tnxcount_plot  %>% print()
```




# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
options(width = 120L)
sessioninfo::session_info()
options(width = 80L)
```
