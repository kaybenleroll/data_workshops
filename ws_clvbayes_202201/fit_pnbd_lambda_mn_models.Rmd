---
title: "Fit the Lambda-Mean P/NBD Models"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    code_folding: hide
    fig_caption: TRUE

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(cmdstanr)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)


source("lib_utils.R")
source("lib_btyd.R")


conflict_lst <- resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "MASS",
    "fitdistrplus")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```







# Load Datasets

We start by re-loading the data required for these models.


## Load Pre-processed Transactional Data


```{r load_customer_cohort_data, echo=TRUE}
customer_cohortdata_tbl <- read_rds("data/customer_cohort_tbl.rds")
customer_cohortdata_tbl %>% glimpse()
```

We also want to load the raw transaction data as we want to transform the data
into a form we now use.

```{r load_transactional_data, echo=TRUE}
retail_transaction_data_tbl <- read_rds("data/retail_data_cleaned_tbl.rds")
retail_transaction_data_tbl %>% glimpse()
```

We also want to load the customer transactional data.

```{r load_customer_transactions_data, echo=TRUE}
customer_transactions_tbl <- read_rds("data/customer_transactions_tbl.rds")
customer_transactions_tbl %>% glimpse()
```


Finally, we want to load the various datasets used to fit the P/NBD models

```{r load_btyd_fitdata, echo=TRUE}
btyd_fitdata_tbl <- read_rds("data/btyd_fitdata_tbl.rds")

btyd_fitdata_tbl %>% glimpse()
```


```{r load_btyd_obs_data, echo=TRUE}
btyd_obs_stats_tbl <- read_rds("data/btyd_obs_stats_tbl.rds")

btyd_obs_stats_tbl %>% glimpse()
```



```{r load_extreme_customers, echo=TRUE}
extreme_customers_tbl <- read_rds("data/extreme_customers_tbl.rds")

extreme_customers_tbl %>% glimpse()
```



# Fit the Hierarchical Lambda-Mean P/NBD Model


```{r setup_workbook_parameters, echo=TRUE}
stan_modeldir <- "stan_models"
stan_codedir  <-   "stan_code"
```


We now compile this model using `CmdStanR`.


```{r display_pnbd_hierlambdamn_model_stancode, echo=FALSE}
read_lines("stan_code/pnbd_hierlambdamn.stan") %>% cat(sep = "\n")
```

We now compile this model using `CmdStanR`.

```{r compile_pnbd_hierlambdamn_stanmodel, echo=TRUE, results="hide"}
pnbd_hierlambdamn_stanmodel <- cmdstan_model(
  "stan_code/pnbd_hierlambdamn.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


## Fit the Model

We then use this compiled model with our data to produce a fit of the data.

```{r fit_pnbd_hierlambdamn_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "pnbd_hierlambdamn"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- btyd_fitdata_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn_p1 = log(0.25) - 0.5 * (0.5)^2,
    lambda_mn_p2 = 1.0,
    
    lambda_cv = 1.00,
    
    mu_mn     = 0.10,
    mu_cv     = 0.60,
    )

pnbd_hierlambdamn_stanfit <- pnbd_hierlambdamn_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          200,
  iter_sampling   =                           50,
  seed            =                         4201,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

pnbd_hierlambdamn_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_pnbd_hierlambdamn_hmc_diagnostics, echo=TRUE, cache=TRUE}
pnbd_hierlambdamn_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_hierlambdamn_traceplots, echo=TRUE}
parameter_subset <- c(
  "lambda[1]", "lambda[2]", "lambda[3]", "lambda[4]",
  "mu[1]",     "mu[2]",     "mu[3]",     "mu[4]"
  )

pnbd_hierlambdamn_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = parameter_subset) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and Mu Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```


A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_pnbd_hierlambdamn_parameter_rhat, echo=TRUE}
pnbd_hierlambdamn_stanfit %>%
  rhat(pars = c("lambda", "mu")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_pnbd_hierlambdamn_parameter_neffratio, echo=TRUE}
pnbd_hierlambdamn_stanfit %>%
  neff_ratio(pars = c("lambda", "mu")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_pnbd_hierlambdamn_parameter_acf, echo=TRUE}
pnbd_hierlambdamn_stanfit$draws() %>%
  mcmc_acf(pars = parameter_subset) +
    ggtitle("Autocorrelation Plot of Sample Values")
```


## Validate the Hierarchical Lambda-Mean Model

```{r construct_pnbd_hierlambdamn_posterior_data, echo=TRUE}
pnbd_hierlambdamn_validation_tbl <- pnbd_hierlambdamn_stanfit %>%
  recover_types(btyd_fitdata_tbl) %>%
  spread_draws(lambda[customer_id], mu[customer_id], p_alive[customer_id]) %>%
  ungroup() %>%
  select(
    customer_id, draw_id = .draw, post_lambda = lambda, post_mu = mu, p_alive
    )

pnbd_hierlambdamn_validation_tbl %>% glimpse()
```

```{r}
knitr::knit_exit()
```



Having constructed our simulations inputs, we now generate our simulations.

```{r generate_pnbd_hierlambdamn_validation_sims, echo=TRUE}
precompute_dir <- "precompute/pnbd_hierlambdamn"

precomputed_tbl <- dir_ls(precompute_dir) %>%
  enframe(name = NULL, value = "sim_file") %>%
  mutate(sim_file = sim_file %>% as.character())


pnbd_hierlambdamn_validsims_lookup_tbl <- pnbd_hierlambdamn_validation_tbl %>%
  group_nest(customer_id, .key = "cust_params") %>%
  mutate(
    sim_file = glue(
      "{precompute_dir}/sims_pnbd_hierlambdamn_{customer_id}.rds"
      )
    )
    

exec_tbl <-  pnbd_hierlambdamn_validsims_lookup_tbl %>%
  anti_join(precomputed_tbl, by = "sim_file")


if(exec_tbl %>% nrow() > 0) {
  exec_tbl %>%
    mutate(
      calc_file = future_map2_lgl(
        sim_file, cust_params,
        run_pnbd_simulations_chunk,
        start_dttm = as.POSIXct("2011-04-01"),
        end_dttm   = as.POSIXct("2011-12-10"),
  
        .options = furrr_options(
          globals  = c(
            "calculate_event_times", "rgamma_mucv", "gamma_mucv2shaperate",
            "generate_pnbd_validation_transactions"
            ),
          packages   = c("tidyverse", "fs"),
          scheduling = FALSE,
          seed       = 4202
          ),
        .progress = TRUE
        )
      )
}

exec_tbl %>% glimpse()

pnbd_hierlambdamn_validsims_lookup_tbl %>% glimpse()
```

We now load all the simulations into a file.

```{r load_pnbd_hierlambdamn_validsims, echo=TRUE, cache=TRUE}
pnbd_hierlambdamn_validsims_tbl <- pnbd_hierlambdamn_validsims_lookup_tbl %>%
  mutate(
    data = map(sim_file, ~ .x %>% read_rds() %>% select(draw_id, sim_tnx_count, sim_tnx_last))
    ) %>%
  select(customer_id, sim_file, data) %>%
  unnest(data)

pnbd_hierlambdamn_validsims_tbl %>% glimpse()
```


```{r construct_pnbd_hierlambdamn_tnx_simulations, echo=TRUE}
tnx_data_tbl <- btyd_obs_stats_tbl %>% 
  semi_join(pnbd_hierlambdamn_validsims_tbl, by = "customer_id")

obs_customer_count  <- tnx_data_tbl %>% nrow()
obs_total_tnx_count <- tnx_data_tbl %>% pull(tnx_count) %>% sum()

pnbd_hierlambdamn_tnx_simsumm_tbl <- pnbd_hierlambdamn_validsims_tbl %>%
  group_by(draw_id) %>%
  summarise(
    .groups = "drop",
    
    sim_customer_count  = length(sim_tnx_count[sim_tnx_count > 0]),
    sim_total_tnx_count = sum(sim_tnx_count)
    )


ggplot(pnbd_hierlambdamn_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_customer_count), binwidth = 10) +
  geom_vline(aes(xintercept = obs_customer_count), colour = "red") +
  labs(
    x = "Simulated Customers With Transactions",
    y = "Frequency",
    title = "Histogram of Count of Customers Transacted",
    subtitle = "Observed Count in Red"
    )

ggplot(pnbd_hierlambdamn_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_total_tnx_count), binwidth = 50) +
  geom_vline(aes(xintercept = obs_total_tnx_count), colour = "red") +
  labs(
    x = "Simulated Transaction Count",
    y = "Frequency",
    title = "Histogram of Count of Total Transaction Count",
    subtitle = "Observed Count in Red"
    )
```





# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
options(width = 120L)
sessioninfo::session_info()
options(width = 80L)
```
