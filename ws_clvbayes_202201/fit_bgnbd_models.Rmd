---
title: "Fit Initial BG/NBD Models"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    code_folding: hide
    fig_caption: TRUE

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(cmdstanr)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)
library(tidyquant)


source("lib_utils.R")
source("lib_btyd.R")


conflict_lst <- resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "MASS",
    "fitdistrplus")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```







# Load Datasets

We start by re-loading the data required for these models.


## Load Pre-processed Transactional Data

```{r load_transactional_data, echo=TRUE}
retail_transaction_data_tbl <- read_rds("data/retail_data_cleaned_tbl.rds")
retail_transaction_data_tbl %>% glimpse()
```

We also want to load the customer transactional data.

```{r load_customer_transactions_data, echo=TRUE}
customer_transactions_tbl <- read_rds("data/customer_transactions_tbl.rds")
customer_transactions_tbl %>% glimpse()
```


Finally, we want to load the various datasets used to fit the P/NBD models

```{r load_btyd_fitdata, echo=TRUE}
btyd_fitdata_tbl <- read_rds("data/btyd_fitdata_tbl.rds")

btyd_fitdata_tbl %>% glimpse()
```


```{r load_btyd_obs_data, echo=TRUE}
btyd_obs_stats_tbl <- read_rds("data/btyd_obs_stats_tbl.rds")

btyd_obs_stats_tbl %>% glimpse()
```



```{r load_extreme_customers, echo=TRUE}
extreme_customers_tbl <- read_rds("data/extreme_customers_tbl.rds")

extreme_customers_tbl %>% glimpse()
```


## Construct Customer Cohorts

Later in this worksheet we will want to create customer cohorts based on the
date of the first transaction for each customer.

```{r construct_customer_cohort_data, echo=TRUE}
customer_cohortdata_tbl <- customer_transactions_tbl %>%
  group_by(customer_id) %>%
  summarise(
    .groups = "drop",
    
    first_tnx_date = min(tnx_timestamp)
    ) %>%
  mutate(
    cohort_qtr = first_tnx_date %>% as.yearqtr(),
    cohort_ym  = first_tnx_date %>% format("%Y %m"),
    
    .after = "customer_id"
    )

customer_cohortdata_tbl %>% glimpse()
```



# Fit Initial BG/NBD Model


```{r setup_workbook_parameters, echo=TRUE}
stan_modeldir <- "stan_models"
stan_codedir  <-   "stan_code"
```


```{r display_bgnbd_fixed_model_stancode, echo=FALSE}
read_lines("stan_code/bgnbd_fixed.stan") %>% cat(sep = "\n")
```

We now compile this model using `CmdStanR`.

```{r compile_bgnbd_fixed_stanmodel, echo=TRUE, results="hide"}
bgnbd_fixed_stanmodel <- cmdstan_model(
  "stan_code/bgnbd_fixed.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


## Fit the Model

We then use this compiled model with our data to produce a fit of the data.

```{r fit_bgnbd_fixed_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "bgnbd_fixed"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- btyd_fitdata_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn = 0.25,
    lambda_cv = 1.00,
    
    p_mn      =  0.10,
    p_k       = 10.00,
    )

bgnbd_fixed_stanfit <- bgnbd_fixed_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          500,
  iter_sampling   =                          500,
  seed            =                         4201,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

bgnbd_fixed_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_bgnbd_fixed_hmc_diagnostics, echo=TRUE, cache=TRUE}
bgnbd_fixed_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_bgnbd_fixed_traceplots, echo=TRUE}
sample_params <- c(
  "lambda[1]", "lambda[2]", "lambda[3]", "lambda[4]", "lambda[5]", "lambda[6]",
  "p[1]",      "p[2]",      "p[3]",      "p[4]",      "p[5]",      "p[6]"
  )

bgnbd_fixed_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = sample_params) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and p Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```


A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_bgnbd_fixed_parameter_rhat, echo=TRUE}
bgnbd_fixed_stanfit %>%
  rhat(pars = c("lambda", "p")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_bgnbd_fixed_parameter_neffratio, echo=TRUE}
bgnbd_fixed_stanfit %>%
  neff_ratio(pars = c("lambda", "p")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_bgnbd_fixed_parameter_acf, echo=TRUE}
bgnbd_fixed_stanfit$draws() %>%
  mcmc_acf(pars = sample_params) +
    ggtitle("Autocorrelation Plot of Sample Values")
```


## Validate the Hierarchical Lambda-Mean Model

We now want to validate the outputs of this model by looking at the posteriors
for both $\lambda$, $\mu$ and `p_alive`, and then running our simulations using
these outputs.

```{r construct_bgnbd_fixed_posterior_data, echo=TRUE}
bgnbd_fixed_validation_tbl <- bgnbd_fixed_stanfit %>%
  recover_types(btyd_fitdata_tbl) %>%
  spread_draws(lambda[customer_id], p[customer_id]) %>%
  ungroup() %>%
  select(
    customer_id, draw_id = .draw, post_lambda = lambda, post_p = p
    )

bgnbd_fixed_validation_tbl %>% glimpse()
```



Having constructed our simulations inputs, we now generate our simulations.

```{r generate_bgnbd_fixed_validation_sims, echo=TRUE}
precompute_dir <- "precompute/bgnbd_fixed"

precomputed_tbl <- dir_ls(precompute_dir) %>%
  enframe(name = NULL, value = "sim_file") %>%
  mutate(sim_file = sim_file %>% as.character())


bgnbd_fixed_validsims_lookup_tbl <- bgnbd_fixed_validation_tbl %>%
  group_nest(customer_id, .key = "cust_params") %>%
  mutate(
    sim_file = glue(
      "{precompute_dir}/sims_bgnbd_fixed_{customer_id}.rds"
      )
    )
    

exec_tbl <-  bgnbd_fixed_validsims_lookup_tbl %>%
  anti_join(precomputed_tbl, by = "sim_file")


if(exec_tbl %>% nrow() > 0) {
  exec_tbl %>%
    mutate(
      calc_file = future_map2_lgl(
        sim_file, cust_params,
        run_bgnbd_simulations_chunk,
        start_dttm = as.POSIXct("2011-04-01"),
        end_dttm   = as.POSIXct("2011-12-10"),
  
        .options = furrr_options(
          globals  = c(
            "calculate_event_times", "rgamma_mucv", "gamma_mucv2shaperate",
            "generate_bgnbd_validation_transactions"
            ),
          packages   = c("tidyverse", "fs"),
          scheduling = FALSE,
          seed       = 4202
          ),
        .progress = TRUE
        )
      )
}

exec_tbl %>% glimpse()

bgnbd_fixed_validsims_lookup_tbl %>% glimpse()
```

We now load all the simulations into a file.

```{r load_bgnbd_fixed_validsims, echo=TRUE, cache=TRUE}
bgnbd_fixed_validsims_tbl <- bgnbd_fixed_validsims_lookup_tbl %>%
  mutate(
    data = map(sim_file, ~ .x %>% read_rds() %>% select(draw_id, sim_tnx_count, sim_tnx_last))
    ) %>%
  select(customer_id, sim_file, data) %>%
  unnest(data)

bgnbd_fixed_validsims_tbl %>% glimpse()
```


We also want to look at how our simulated data compares to the transaction
data that occurred after Apr 1 2011.

```{r construct_bgnbd_fixed_tnx_simulations, echo=TRUE}
tnx_data_tbl <- btyd_obs_stats_tbl %>% 
  semi_join(bgnbd_fixed_validsims_tbl, by = "customer_id")

obs_customer_count  <- tnx_data_tbl %>% nrow()
obs_total_tnx_count <- tnx_data_tbl %>% pull(tnx_count) %>% sum()

bgnbd_fixed_tnx_simsumm_tbl <- bgnbd_fixed_validsims_tbl %>%
  group_by(draw_id) %>%
  summarise(
    .groups = "drop",
    
    sim_customer_count  = length(sim_tnx_count[sim_tnx_count > 0]),
    sim_total_tnx_count = sum(sim_tnx_count)
    )


ggplot(bgnbd_fixed_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_customer_count), binwidth = 10) +
  geom_vline(aes(xintercept = obs_customer_count), colour = "red") +
  labs(
    x = "Simulated Customers With Transactions",
    y = "Frequency",
    title = "Histogram of Count of Customers Transacted",
    subtitle = "Observed Count in Red"
    )

ggplot(bgnbd_fixed_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_total_tnx_count), binwidth = 50) +
  geom_vline(aes(xintercept = obs_total_tnx_count), colour = "red") +
  labs(
    x = "Simulated Transaction Count",
    y = "Frequency",
    title = "Histogram of Count of Total Transaction Count",
    subtitle = "Observed Count in Red"
    )
```

So we have gone from a strong under-estimation bias to a strong over-estimation
bias, but the model is fitting much faster, so working on this.







# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
options(width = 120L)
sessioninfo::session_info()
options(width = 80L)
```
