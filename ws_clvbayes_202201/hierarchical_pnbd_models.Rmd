---
title: "Adding Hierarchy to the P/NBD Model"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    code_folding: hide
    fig_caption: TRUE

  html_document:
    fig_caption: yes
    theme: spacelab #sandstone #spacelab #flatly
    highlight: pygments
    number_sections: TRUE
    toc: TRUE
    toc_depth: 2
    toc_float:
      smooth_scroll: FALSE

  pdf_document: default
---


```{r import_libraries, echo=FALSE, message=FALSE}
library(conflicted)
library(tidyverse)
library(scales)
library(cowplot)
library(directlabels)
library(magrittr)
library(rlang)
library(fs)
library(purrr)
library(furrr)
library(glue)
library(cmdstanr)
library(brms)
library(posterior)
library(bayesplot)
library(tidybayes)


source("lib_utils.R")
source("lib_btyd.R")


conflict_lst <- resolve_conflicts(
  c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "MASS",
    "fitdistrplus")
  )


knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    11
  )

options(
  width = 80L,
  warn  = 1,
  mc.cores = parallel::detectCores()
  )

theme_set(theme_cowplot())

set.seed(42)

plan(multisession)
```

We now turn our attention to trying to capture our uncertainty in prior
parameters by adding them to the model.

We first need to load our data.

```{r load_synthetic_data, echo=TRUE}
fit_1000_data_tbl  <- read_rds("data/fit_1000_longframe_data_tbl.rds")
fit_10000_data_tbl <- read_rds("data/fit_10000_longframe_data_tbl.rds")

customer_summarystats_tbl <- read_rds("data/customer_summarystats_longframe_tbl.rds")
customer_transactions_tbl <- read_rds("data/synthdata_longframe_transactions_tbl.rds")

obs_2019_stats_tbl <- read_rds("data/longframe_obs_2019_stats_tbl.rds")
```


# Fit First Hierarchical Model

We now want to add a hierarchy to the model by adding hierarchical priors to
our P/NBD model.

```{r setup_workbook_parameters, echo=TRUE}
stan_modeldir <- "stan_models"
stan_codedir  <-   "stan_code"
```


We start with our Stan model.

```{r display_pnbd_hiermu_model_stancode, echo=FALSE}
read_lines("stan_code/pnbd_hiermu.stan") %>% cat(sep = "\n")
```

This file contains a few new features of Stan - named file includes and
user-defined functions - `calculate_pnbd_loglik`. We look at this file here:

```{r display_util_functions_stancode, echo=FALSE}
read_lines("stan_code/util_functions.stan") %>% cat(sep = "\n")
```

We now compile this model using `CmdStanR`.

```{r compile_pnbd_hiermu_stanmodel, echo=TRUE, results="hide"}
pnbd_hiermu_stanmodel <- cmdstan_model(
  "stan_code/pnbd_hiermu.stan",
  include_paths =   stan_codedir,
  pedantic      =           TRUE,
  dir           =  stan_modeldir
  )
```


We then use this compiled model with our data to produce a fit of the data.

```{r fit_pnbd_hiermu_stanmodel, echo=TRUE, cache=TRUE}
stan_modelname <- "pnbd_hiermu"
stanfit_prefix <- str_c("fit_", stan_modelname) 

stan_data_lst <- fit_1000_data_tbl %>%
  select(customer_id, x, t_x, T_cal) %>%
  compose_data(
    lambda_mn = 0.25,
    lambda_cv = 1.00,
    
    mu_mn_p1  = log(0.1) - 0.5 * (0.5)^2,
    mu_mn_p2  = 0.5,
    
    mu_cv_p1  = log(1) - 0.5 * (0.2)^2,
    mu_cv_p2  = 0.2,
    )

pnbd_hiermu_stanfit <- pnbd_hiermu_stanmodel$sample(
  data            =                stan_data_lst,
  chains          =                            4,
  iter_warmup     =                          500,
  iter_sampling   =                          500,
  seed            =                         4201,
  save_warmup     =                         TRUE,
  output_dir      =                stan_modeldir,
  output_basename =               stanfit_prefix,
  )

pnbd_hiermu_stanfit$summary()
```

We have some basic HMC-based validity statistics we can check.

```{r calculate_pnbd_hiermu_hmc_diagnostics, echo=TRUE}
pnbd_hiermu_stanfit$cmdstan_diagnose()
```


## Visual Diagnostics of the Sample Validity

Now that we have a sample from the posterior distribution we need to create a
few different visualisations of the diagnostics.

```{r plot_lambda_traceplots_warmup, echo=TRUE}
parameter_subset <- c(
  "s", "beta", "mu_mn", "mu_cv",
  "lambda[1]", "lambda[2]", "lambda[3]", "lambda[4]",
  "mu[1]",     "mu[2]",     "mu[3]",     "mu[4]"
  )

pnbd_hiermu_stanfit$draws(inc_warmup = TRUE) %>%
  mcmc_trace(
    pars     = parameter_subset,
    n_warmup = 500
    ) +
  ggtitle("Full Traceplots of Some Lambda and Mu Values")
```


As the warmup is skewing the y-axis somewhat, we repeat this process without
the warmup.

```{r plot_lambda_traceplots_nowarmup, echo=TRUE}
pnbd_hiermu_stanfit$draws(inc_warmup = FALSE) %>%
  mcmc_trace(pars = parameter_subset) +
  expand_limits(y = 0) +
  labs(
    x = "Iteration",
    y = "Value",
    title = "Traceplot of Sample of Lambda and Mu Values"
    ) +
  theme(axis.text.x = element_text(size = 10))
```

A common MCMC diagnostic is $\hat{R}$ - which is a measure of the 'similarity'
of the chains.

```{r plot_pnbd_hiermu_parameter_rhat, echo=TRUE}
pnbd_hiermu_stanfit %>%
  rhat(pars = c("lambda", "mu", "s", "beta", "mu_mn", "mu_cv")) %>%
  mcmc_rhat() +
    ggtitle("Plot of Parameter R-hat Values")
```

Related to this quantity is the concept of *effective sample size*, $N_{eff}$,
an estimate of the size of the sample from a statistical information point of
view.


```{r plot_pnbd_hiermu_parameter_neffratio, echo=TRUE}
pnbd_hiermu_stanfit %>%
  neff_ratio(pars = c("lambda", "mu", "s", "beta", "mu_mn", "mu_cv")) %>%
  mcmc_neff() +
    ggtitle("Plot of Parameter Effective Sample Sizes")
```

Finally, we also want to look at autocorrelation in the chains for each
parameter.

```{r plot_pnbd_hiermu_parameter_acf, echo=TRUE}
pnbd_hiermu_stanfit$draws() %>%
  mcmc_acf(pars = parameter_subset) +
    ggtitle("Autocorrelation Plot of Sample Values")
```

As before, this first fit has a comprehensive run of fit diagnostics, but for
the sake of brevity in later models we will show only the traceplots once we
are satisfied with the validity of the sample.


## Validate the Hier-Mu Model Fit

We now want to validate this model by using our simulation technique.

We first extract our posterior by customer, and use this as the basis of our
simulations.

```{r construct_pnbd_hiermu_posterior_data, echo=TRUE}
pnbd_hiermu_validation_tbl <- pnbd_hiermu_stanfit %>%
  recover_types(fit_1000_data_tbl) %>%
  spread_draws(lambda[customer_id], mu[customer_id], p_alive[customer_id]) %>%
  ungroup() %>%
  select(customer_id, draw_id = .draw, post_lambda = lambda, post_mu = mu, p_alive)

pnbd_hiermu_validation_tbl %>% glimpse()
```

Having constructed our simulations inputs, we now generate our simulations.

```{r generate_pnbd_hiermu_validation_sims, echo=TRUE}
pnbd_hiermu_validsims_tbl <- pnbd_hiermu_validation_tbl %>%
  group_nest(customer_id, .key = "cust_params") %>%
  mutate(
    sim_file = glue(
      "precompute/pnbd_hiermu/sims_pnbd_hiermu_{customer_id}.rds"
      ),
    chunk_data = future_map2(
      sim_file, cust_params,
      run_pnbd_simulations_chunk,

      .options = furrr_options(
        globals  = c(
          "calculate_event_times", "rgamma_mucv", "gamma_mucv2shaperate",
          "generate_pnbd_validation_transactions"
          ),
        packages   = c("tidyverse", "fs"),
        scheduling = FALSE,
        seed       = 421
        ),
      .progress = TRUE
      )
    ) %>%
  select(-cust_params) %>%
  unnest(chunk_data)


pnbd_hiermu_validsims_tbl %>% glimpse()
```



```{r construct_pnbd_hiermu_1000_validation_data, echo=TRUE}
pnbd_hiermu_1000_validation_tbl <- pnbd_hiermu_validsims_tbl %>%
  group_by(customer_id) %>%
  summarise(
    .groups = "drop",
    
    sim_count = list(map_int(sim_data, nrow))
    ) %>%
  left_join(obs_2019_stats_tbl, by = "customer_id") %>%
  replace_na(list(tnx_count = 0)) %>%
  mutate(
    tnx_count_qval = map2_dbl(sim_count, tnx_count, ~ ecdf(.x)(.y))
    )

pnbd_hiermu_1000_validation_tbl %>% glimpse()
```



```{r construct_pnbd_hiermu_tnx_simulations, echo=TRUE}
tnx_data_tbl <- obs_2019_stats_tbl %>% 
  semi_join(pnbd_hiermu_validsims_tbl, by = "customer_id")

obs_customer_count  <- tnx_data_tbl %>% nrow()
obs_total_tnx_count <- tnx_data_tbl %>% pull(tnx_count) %>% sum()

pnbd_hiermu_tnx_simsumm_tbl <- pnbd_hiermu_validsims_tbl %>%
  group_by(draw_id) %>%
  summarise(
    .groups = "drop",
    
    sim_customer_count  = length(sim_tnx_count[sim_tnx_count > 0]),
    sim_total_tnx_count = sum(sim_tnx_count)
    )


ggplot(pnbd_hiermu_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_customer_count), binwidth = 1) +
  geom_vline(aes(xintercept = obs_customer_count), colour = "red") +
  labs(
    x = "Simulated Customers With Transactions",
    y = "Frequency",
    title = "Histogram of Count of Customers Transacted",
    subtitle = "Observed Count in Red"
    )

ggplot(pnbd_hiermu_tnx_simsumm_tbl) +
  geom_histogram(aes(x = sim_total_tnx_count), binwidth = 5) +
  geom_vline(aes(xintercept = obs_total_tnx_count), colour = "red") +
  labs(
    x = "Simulated Transaction Count",
    y = "Frequency",
    title = "Histogram of Count of Total Transaction Count",
    subtitle = "Observed Count in Red"
    )
```



# R Environment

```{r show_session_info, echo=TRUE, message=TRUE}
options(width = 120L)
sessioninfo::session_info()
options(width = 80L)
```
