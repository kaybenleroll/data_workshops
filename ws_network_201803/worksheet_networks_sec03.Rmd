---
title: "Dublin Data Science Workshop on the Statistical Analysis of Networks"
subtitle: Section 3
author: "Mick Cooney <mickcooney@gmail.com>"
date: "Monday, March 26 2018"
output:
  html_document:
    fig_caption: yes
    number_sections: yes
    theme: cerulean
    toc: yes
  word_document:
    toc: yes
  pdf_document: default
---

```{r knit_opts, include = FALSE}
knitr::opts_chunk$set(tidy  = FALSE
                     ,cache = FALSE
                     ,message = FALSE
                     ,warning = FALSE
                     ,fig.height =  8
                     ,fig.width  = 11)

library(tidyverse)
library(scales)
library(cowplot)

library(ggnetwork)
library(igraph)
library(igraphdata)
library(sand)


options(width = 80L
       ,warn  = 1
        )

set.seed(42)


source('data_setup.R')

source('custom_functions.R')
```





# Random Graph Models

We now move on to modelling graph data using statistical methods.

To begin, we start with very simple generative processes for graphs,
investigating how we can use these methods to approximate data we have.

## Traditional Models

We start with basic statistical models where models are produced purely at
random to match basic measures of graphs such as node and edge count, degree
distributions and so on.

The building block for these are *Erdos-Renyi* models, probably the simplest
models we can produce.


### Erdos-Renyi Graph Models

The simplest random graph model is one where we have a fixed number of nodes
and have either a fixed count of edges with equally likely probability - the 
$G(n,m)$ model, or we assign each edge a fixed probability of occurring - the
$G(n,p)$ model.

We start with the $G(n,m)$ model on a network with 50 nodes so that processing
and visualisation is fast.

```{r show_gnm_models, echo=TRUE}
gnmsample_igraph <- sample_gnm(50, 75)

ggplot(ggnetwork(gnmsample_igraph, layout = 'fruchtermanreingold')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,m) Graph') +
    theme_blank()
    
ggplot(ggnetwork(gnmsample_igraph, layout = 'circle')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,m) Graph with Circular Layout') +
    theme_blank()

```

Similarly, we generate a $G(n, p)$ graph.

```{r show_gnp_models, echo=TRUE}
gnpsample_igraph <- sample_gnp(50, 0.05)

ggplot(ggnetwork(gnpsample_igraph, layout = 'fruchtermanreingold')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,p) Graph') +
    theme_blank()
    
ggplot(ggnetwork(gnpsample_igraph, layout = 'circle')
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample G(n,p) Graph with Circular Layout') +
    theme_blank()
```


### Generalised Random Graph Models

Expanding this concept, we can generate graphs based on more advanced measures
of the graph, such as the degree distribution.

To show how this works, we create a 45-node graph where each node has a degree between
1 and 3.

```{r sample_degree_dist_graph, echo=TRUE}
sample_degreedist <- sample(1:3, 45, replace = TRUE)

degdistsample_igraph <- sample_degseq(sample_degreedist, method = 'simple.no.multiple')

ggplot(ggnetwork(degdistsample_igraph)
      ,aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_edges() +
    geom_label(aes(label = vertex.names)) +
    ggtitle('Sample Degree Distribution Graph') +
    theme_blank()
```

More advanced algorithms exist to construct random graphs on other
characteristics, but most of those rely on Markov Chain Monte Carlo methods
and are beyond the scope of this workshop.

### Assessing Random Graph Models

Now that we have a few methods for producing these random graphs, the next
logical issue is assessing how well these models capture aspects of our data.

#### Florentine Marriage Network

As an example, we use the Florentine dataset, and produce some random graphs
that match our data and compare the other measures such as clustering, diameter
and average path length to what our models produce.

*NOTE:* This code may look a little cryptic and overly-concise at first, as I use
functional methods to produce the simulations. There is nothing fancy
happening here, so look up the functions in `purrr` if you get confused.

```{r model_florentine_data_gnm, echo=TRUE}
n_iter <- 1000

flor_count_node <- gorder(florence_igraph)
flor_count_edge <- gsize (florence_igraph)

sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_gnm(n = flor_count_node, flor_count_edge))
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

We do something similar for the G(n,p) model

```{r model_florentine_data_gnp, echo=TRUE}
n_iter <- 1000

flor_count_node <- gorder(florence_igraph)
flor_count_edge <- gsize (florence_igraph)

edge_prop <- flor_count_edge / (0.5 * flor_count_node * (flor_count_node-1))


sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_gnp(n = flor_count_node, p = edge_prop))
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

The $G(n,p)$ model looks very similar, as expected.

Finally, We also try the degree distribution sample


```{r model_florentine_data_degreedist, echo=TRUE}
flor_degdist <- igraph::degree(florence_igraph)


sim_data_tbl <- data_frame(sim_id = 1:n_iter) %>%
    mutate(graph      = rerun(n_iter, sample_degseq(flor_degdist))
          ,trans      = map_dbl(graph, transitivity)
          ,diam       = map_dbl(graph, diameter)
          ,meandist   = map_dbl(graph, mean_distance)
          ,max_degree = map_dbl(graph, function(x) x %>% igraph::degree() %>% max)
           )

graph_vals_tbl <- data_frame(
    parameter = c('trans','diam','meandist', 'max_degree')
   ,graph_val = c(florence_igraph %>% transitivity
                 ,florence_igraph %>% diameter
                 ,florence_igraph %>% mean_distance
                 ,florence_igraph %>% igraph::degree() %>% max
                 )
    )

plot_data_tbl <- sim_data_tbl %>%
    dplyr::select(-graph) %>%
    gather('parameter','value', -sim_id)


ggplot(plot_data_tbl) +
    geom_histogram(aes(x = value), bins = 50) +
    geom_vline(aes(xintercept = graph_val), colour = 'red', data = graph_vals_tbl) +
    facet_wrap(~parameter, scales = 'free') +
    scale_y_continuous(label = comma) +
    xlab('Value') +
    ylab('Count')
```

WHile small and useful to illustrate the basics, the Florentine marriage network
may not be a sound example for the purposes of illustrating the quality of these
statistical models.

Due to its small size, the number of possible networks with these node and edge
counts is low, so it is likely that any random graph will agree with it because
of this.

It is more instructive to try larger networks, and see how effective
these simple models are at reconstructing them.

*SPOILER ALERT*: They kinda suck at it


#### Lazega Network

We now try the above models on the Lazega data

```{r model_lazega_data_gnm, echo=TRUE}
lazega_count_node <- gorder(lazega_igraph)
lazega_count_edge <- gsize (lazega_igraph)

run_gnm <- function() sample_gnm(n = lazega_count_node, lazega_count_edge)

lazega_gnm_lst <- run_network_model_assessment(lazega_igraph, run_gnm, n_iter = 1000)

plot(lazega_gnm_lst$assess_plot)
```

As you can see, the Lazega network is larger than the Florentine network
(though still small in absolute terms) and we already see that the observed
values of the network differ from our simulations.

The clustering coefficient in the Lazega network in particular is not well
captured by the model.

We try the degree distribution model too, and see if that does a better job.

```{r model_lazega_data_degdist, echo=TRUE}
lazega_degdist <- lazega_igraph %>% igraph::degree()

run_degdist <- function() sample_degseq(lazega_degdist)

lazega_degdist_lst <- run_network_model_assessment(lazega_igraph, run_degdist, n_iter = 1000)

plot(lazega_degdist_lst$assess_plot)
```

We see similar results to before, but once again the clustering is not well
captured.


## Mechanistic Random Graph Models

Our basic random graph models do not capture the higher levels of clustering
observed in real-world networks.




### Small World Models




### Preferential Attachment Models


## Assessing Models


# Statistical Models for Graphs

