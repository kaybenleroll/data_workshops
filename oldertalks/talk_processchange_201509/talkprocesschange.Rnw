\documentclass[11pt]{beamer}

\makeatletter
\g@addto@macro\@verbatim\tiny
\makeatother

\usepackage{graphicx}
\usepackage{eurosym}
\usepackage{hyperref}



\usetheme[compress]{Berlin}


\title[Monitoring Process Change with Bayesian Methods]{Monitoring Process Change with Bayesian Methods}
\author{Mick Cooney}
\date{2 September 2015}

<<setoptions, include=TRUE, echo=FALSE, cache=FALSE, results='hide'>>=
opts_knit$set(root.dir = ".")

opts_chunk$set(fig.path = '.');
opts_chunk$set(fig.align = 'center');
opts_chunk$set(out.width  = '11cm');
opts_chunk$set(out.height =  '6cm');

opts_chunk$set(size = 'tiny');

set.seed(42);

@

<<init, echo=FALSE, cache=FALSE, results='hide', warning=FALSE, message=FALSE>>=
dev_mode(TRUE);

require(ggplot2);
require(data.table);
require(scales);
require(reshape2);
require(xts);

source("lib.R");
@



\begin{document}

\begin{frame}
\titlepage
\end{frame}



%%%
%%%  Section: Introduction
%%%

\section{Introduction}


%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Structure of Talk}

\begin{itemize}
    \item Discussion of Problem
    \item Bayesian Analysis and the Beta Distribution
    \item Adding Layers of Noise
    \item Distribution Distances and f-divergences
\end{itemize}

\end{frame}



%%%
%%%  Section: Introduction
%%%

\section{Problem Discussion}


%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Monitoring Process Change}

\begin{itemize}
  \item NOT Change-point Analysis
  \item Time of change known - want to measure change effect
  \item Have measured metrics
  \item Need to determine change vs noise
  \item Generic technique for the problem
\end{itemize}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Sales-call Conversions}

\begin{itemize}
  \item Assume a binary outcome
  \item Conversion rate of sales calls to actual sales
  \item Amount irrelevant
  \item Data summarised monthly
  \item Change due to internal improvements leading to faster turnaround
\end{itemize}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Sales-call Conversions}

\begin{itemize}
  \item Assume a binary outcome (0 or 1)
  \item Conversion rate of sales calls to actual sales
  \item Amount irrelevant
  \item Data summarised monthly
  \item Change due to internal improvements leading to faster turnaround
\end{itemize}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Generating Data}

Want to generate time-series for $\theta$, use normal distribution:

<<generating_data, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=

generate_process_rates <- function(mu0 = 0.10, sd0 = 0.03, mu1 = 0.15, sd1 = 0.03,
                                   start_date  = as.Date("2010-01-01"),
                                   end_date    = as.Date("2015-03-01"),
                                   change_date = as.Date("2014-01-01")) {

    month_vector <- as.yearmon(seq(start_date, end_date, by = "month"));
    switch_month <- as.yearmon(change_date);

    switch_idx <- match(switch_month, month_vector);

    pre_rate  <- rnorm(switch_idx - 1, mu0, sd0);
    post_rate <- rnorm(length(month_vector) - switch_idx + 1, mu1, sd1);

    rate_dt <- data.table(rate_date = as.Date(month_vector), underlying_rate = c(pre_rate, post_rate));

    return(rate_dt)
}
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]

<<generating_data_plot, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='5.5cm'>>=
plot_rate_dt <- generate_process_rates(mu0 = 0.10, sd0 = 0.02, mu1 = 0.15, sd1 = 0.03);

qplot(rate_date, underlying_rate, data = plot_rate_dt, geom = 'line', ylim = c(0, 0.21),
      xlab = 'Date', ylab = 'Conversion Rate');
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]

<<generating_data_extra_funcs, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
generate_counts <- function(rate_dt, month_count) {
    rate_dt <- data.table(rate_dt, month_count = month_count);

    rate_dt[, conversion_count := mapply(rbinom, n = 1, month_count, underlying_rate)];
    rate_dt[, conversion_rate  := conversion_count / month_count];

    return(rate_dt);
}

generate_yearly_data <- function(rate_dt) {
    year_dt <- rate_dt[, list(a = sum(conversion_count), b = sum(month_count - conversion_count)),
                         by = list(data_year = format(rate_date, '%Y'))];
    year_dt[, c("cum_a", "cum_b") := list(cumsum(a) + 1, cumsum(b) + 1)];

    distrib_dt <- year_dt[, generate_beta_plot_data(cum_a, cum_b), by = data_year];

    return(distrib_dt);
}

generate_beta_plot_data <- function(a, b) {
    theta     <- seq(0, 1, by = 0.0001);
    prob_dens <- dbeta(theta, a, b);

    return(data.table(theta = theta, prob_dens = prob_dens));
}
@

\end{frame}



%%%
%%%  Section: Other Concepts
%%%

\section{Bayesian Analysis}

%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Bayes Rule}

\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]

\noindent Continuous Form:

\[ p(\theta|D) = \int p(D|\theta) \, p(\theta) \, d\theta \]

\noindent
where
\begin{eqnarray*}
  p(\theta)   && \text{Prior distribution for $\theta$} \\
  p(D|\theta) && \text{Probability of seeing data $D$ given value $\theta$} \\
  p(\theta|D) && \text{Posterior distribution for $\theta$}
\end{eqnarray*}


\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Binomial Likelihood}

For single binomial trial with probability $\theta$ and outcome $y$:

\[ p(y|\theta) = \theta^y (1 - \theta)^{1-y} \]

For $n$ trials with $k$ successes:

\[ p(k|\theta) = \left(\frac{n}{k}\right) \theta^k (1 - \theta)^{n-k} \]


\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Beta Distribution}

\[ X \sim Beta(\alpha, \beta) \]

\begin{itemize}
  \item Parameterised by two parameters $\alpha$, $\beta$
  \item Correspond to assumed prior success/fail counts
  \item Simple to do update with new data
\end{itemize}

\[ p(\theta|D) = Beta(\alpha + k, \beta + n - k) \]

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]

<<plot_beta_distributions_1, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
theta_seq <- seq(0, 1, by = 0.001);

p1 <- qplot(theta_seq, dbeta(theta_seq, 1, 1), geom = 'line'
           , xlab = expression(theta), ylab = 'Probability Density',
           , main = 'B(1, 1) Density Plot');

p2 <- qplot(theta_seq, dbeta(theta_seq, 5, 5), geom = 'line'
          , xlab = expression(theta), ylab = 'Probability Density',
          , main = 'B(5, 5) Density Plot');

p3 <- qplot(theta_seq, dbeta(theta_seq, 10, 10), geom = 'line'
          , xlab = expression(theta), ylab = 'Probability Density',
          , main = 'B(10, 10) Density Plot');

p4 <- qplot(theta_seq, dbeta(theta_seq, 5, 15), geom = 'line'
          , xlab = expression(theta), ylab = 'Probability Density',
          , main = 'B(5, 15) Density Plot');

grid.arrange(p1, p2, p3, p4, ncol = 2);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]

<<plot_beta_distributions_2, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=

data1_dt <- generate_beta_plot_data(2, 2);
invisible(data1_dt[, label := 'Beta(2,2)']);

data2_dt <- generate_beta_plot_data(10, 10);
invisible(data2_dt[, label := 'Beta(10,10)']);

data3_dt <- generate_beta_plot_data(100, 100);
invisible(data3_dt[, label := 'Beta(100,100)']);

plotdata_dt = rbind(data1_dt, data2_dt, data3_dt);

qplot(theta, prob_dens, data = plotdata_dt, geom = 'line', colour = label
      , xlab = expression(theta), ylab = 'Probability Density'
      , main = 'Comparison Plot for Beta Distributions');
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{First Pass at the Problem}

<<set_conversion_plots, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
set_conversion_rate_data_dt  <- generate_process_rates(mu0 = 0.10, mu1 = 0.15, sd0 = 0, sd1 = 0);
set_conversion_count_data_dt <- generate_counts(set_conversion_rate_data_dt, month_count = 500);

plot_dt <- melt(set_conversion_count_data_dt[, list(rate_date = as.Date(rate_date), underlying_rate, conversion_rate)]
               , id.vars = 'rate_date', variable.name = 'rate_type');

p1 <- qplot(rate_date, value, data = plot_dt, geom = 'line', ylim = c(0, 0.2), colour = rate_type
            , xlab = 'Date', ylab = 'Set Conversion Rate');

set_conversion_yearly_data_dt <- generate_yearly_data(set_conversion_count_data_dt);

p2 <- qplot(theta, prob_dens, data = set_conversion_yearly_data_dt, geom = 'line'
            , colour = data_year, xlim = c(0.075, 0.125), xlab = expression(theta), ylab = "Probability Density");

grid.arrange(p1, p2, nrow = 2);
@
\end{frame}



%%%
%%%  Section: Pricing Mortality Swaps
%%%

\section{Adding Noise}

%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Randomising Counts per Month}

\begin{itemize}
  \item More random noise
  \item Call counts per month fixed (500 per month)
  \item Model instead as Poisson process
\end{itemize}

\[ C \sim Pois(500) \]

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Randomising Counts per Month}

<<month_count_plots, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
month_count_rate_data_dt  <- generate_process_rates(mu0 = 0.10, mu1 = 0.15, sd0 = 0, sd1 = 0);
month_count_count_data_dt <- generate_counts(month_count_rate_data_dt, month_count = rpois(dim(month_count_rate_data_dt)[1], 500));

plot_dt <- melt(month_count_count_data_dt[, list(rate_date = as.Date(rate_date), underlying_rate, conversion_rate)]
                , id.vars = 'rate_date', variable.name = 'rate_type');

p1 <- qplot(rate_date, value, data = plot_dt, geom = 'line', ylim = c(0, 0.2), colour = rate_type
            , xlab = 'Date', ylab = 'Set Conversion Rate');


month_count_yearly_data_dt <- generate_yearly_data(month_count_count_data_dt);

p2 <- qplot(theta, prob_dens, data = month_count_yearly_data_dt, geom = 'line'
            , colour = data_year
            , xlim = c(0.075, 0.125)
            , xlab = expression(theta), ylab = "Probability Density");

grid.arrange(p1, p2, nrow = 2);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Stochastic Conversion Rate}

\begin{itemize}
  \item Add noise to the conversion rate
  \item Model underlying rate with normal distribution
  \item Noise on conversion rate and monthly count
\end{itemize}

\[ \theta \sim \mathcal{N}(\mu, \sigma) \]

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Stochastic Conversion Rate}

<<stochastic_rate_plots, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
stochastic_rate_rate_data_dt  <- generate_process_rates(mu0 = 0.10, mu1 = 0.15, sd0 = 0.02, sd1 = 0.02);
stochastic_rate_count_data_dt <- generate_counts(stochastic_rate_rate_data_dt, month_count = rpois(dim(stochastic_rate_rate_data_dt)[1], 500));

plot_dt <- melt(stochastic_rate_count_data_dt[, list(rate_date = as.Date(rate_date), underlying_rate, conversion_rate)]
                , id.vars = 'rate_date', variable.name = 'rate_type');

p1 <- qplot(rate_date, value, data = plot_dt, geom = 'line', ylim = c(0, 0.2), colour = rate_type
            , xlab = 'Date', ylab = 'Stochastic Conversion Rate');


stochastic_rate_yearly_data_dt <- generate_yearly_data(stochastic_rate_count_data_dt);

p2 <- qplot(theta, prob_dens, data = stochastic_rate_yearly_data_dt, geom = 'line'
            , colour = data_year, xlim = c(0.075, 0.125), xlab = expression(theta), ylab = "Probability Density");

grid.arrange(p1, p2, nrow = 2);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Taking a Step Back}

<<empirical_yearly_plots, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
stochastic_yearly_rate_dt <- stochastic_rate_count_data_dt[, list(conversion = sum(conversion_count)
                                                                  , month    = sum(month_count)
                                                                  , rate     = sum(conversion_count) / sum(month_count)),
                                                           by = list(year = as.numeric(format(rate_date, "%Y")))];

stochastic_empirical_rate_plot <- qplot(year, rate, data = stochastic_yearly_rate_dt, geom = 'line', ylim = c(0, 0.3));

plotdata_dt <- stochastic_rate_count_data_dt[, list(converted = sum(conversion_count)
                                                    , calls   = sum(month_count)
                                                    , rate    = sum(conversion_count) / sum(month_count)),
                                             by = list(year = as.numeric(format(rate_date, "%Y")))]

qplot(year, rate, data = plotdata_dt, geom = 'line', xlab = 'Year', ylab = 'Conversion Rate', ylim = c(0, 0.2))
@

Inconsistent?

\end{frame}



%%%
%%%  Section: Pricing Mortality Swaps
%%%

\section{Prior Data}


%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Building a New Prior}

\begin{itemize}
  \item Balancing act
  \item Try 6 months, use $\theta$ from data
  \item Re-parameterize $Beta(\alpha, \beta)$
\end{itemize}

\[ Beta(\alpha, \beta) = Beta(\mu K, (1 - \mu) K) \]

\begin{eqnarray*}
\mu &=& 0.0997\\
K   &=& 6,000
\end{eqnarray*}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Using the New Prior}

<<sixmonth_yearly_plots, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
mu <- 0.0997;
K  <- 6000;

sixmonths_data_dt <- stochastic_rate_count_data_dt[rate_date >= as.Date('2014-01-01') & rate_date <= as.Date('2014-06-30')
                                                   , list(rate_date
                                                          , a = cumsum(conversion_count)
                                                          , b = cumsum(month_count) - cumsum(conversion_count))];

sixmonths_newparams_dt <- sixmonths_data_dt[, list(rate_date, new_a = (mu * K) + a, new_b = ((1 - mu) * K) + b)];
sixmonths_plotdata_dt  <- sixmonths_newparams_dt[, generate_beta_plot_data(new_a, new_b), by = rate_date];

# Create a character column for the date to help with plotting
invisible(sixmonths_plotdata_dt[, plotdate := format(rate_date, '%Y%m')]);

qplot(theta, prob_dens, data = sixmonths_plotdata_dt[theta >= 0.05 & theta <= 0.15]
      , geom = 'line', colour = plotdate, xlab = expression(theta), ylab = 'Probability Density');
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Using a Higher $\mu$}

Before:

\[ \mu_1 \sim \mathcal{N}(0.1, 0.02) \rightarrow \mu_2 \sim \mathcal{N}(0.15, 0.02) \]


Now:

\[ \mu_1 \sim \mathcal{N}(0.4, 0.08) \rightarrow \mu_2 \sim \mathcal{N}(0.45, 0.08) \]

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Analysis for $\mu = 0.40$}

<<highbase_plots_1, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
highbase_rate_data_dt  <- generate_process_rates(mu0 = 0.40, mu1 = 0.45, sd0 = 0.08, sd1 = 0.08);
highbase_count_data_dt <- generate_counts(highbase_rate_data_dt
                                          , month_count = rpois(dim(highbase_rate_data_dt)[1], 500));

plot_dt <- melt(highbase_count_data_dt[, list(rate_date = as.Date(rate_date), underlying_rate, conversion_rate)]
                , id.vars = 'rate_date', variable.name = 'rate_type');

qplot(rate_date, value, data = plot_dt, geom = 'line', ylim = c(0, 0.8), colour = rate_type
      , xlab = 'Date', ylab = 'Stochastic Conversion Rate');
@

Very hard to spot a change!

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Analysis for $\mu = 0.40$}

<<highbase_plots_2, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
high_mu <- highbase_count_data_dt[rate_date < as.Date('2014-01-01'), sum(conversion_count) / sum(month_count)];
high_K  <- 6000;

highbase_data_dt <- highbase_count_data_dt[rate_date >= as.Date('2014-01-01') & rate_date <= as.Date('2014-06-30')
                                           , list(rate_date
                                                  , a = cumsum(conversion_count)
                                                  , b = cumsum(month_count) - cumsum(conversion_count))];

highbase_newparams_dt <- highbase_data_dt[, list(rate_date, new_a = (high_mu * high_K) + a, new_b = ((1 - high_mu) * high_K) + b)];
highbase_plotdata_dt  <- highbase_newparams_dt[, generate_beta_plot_data(new_a, new_b), by = rate_date];

invisible(highbase_plotdata_dt[, plotdate := format(rate_date, '%Y%m')]);
qplot(theta, prob_dens, data = highbase_plotdata_dt[theta >= 0.35 & theta <= 0.50]
      , geom = 'line', colour = plotdate, xlab = expression(theta), ylab = 'Probability Density');
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]

<<highbase_plots_3, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
plotdata_dt <- highbase_count_data_dt[, list(converted = sum(conversion_count)
                                             , calls   = sum(month_count)
                                             , rate    = sum(conversion_count) / sum(month_count)),
                                       by = list(year = as.numeric(format(rate_date, "%Y")))]

qplot(year, rate, data = plotdata_dt, geom = 'line', xlab = 'Year', ylab = 'Conversion Rate', ylim = c(0, 0.5))
@

\end{frame}



%%%
%%%  Section: f-divergences
%%%

\section{f-divergences}

%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Differences between Distributions}

A \emph{metric} or \emph{distance}

\[ d: X \times X \rightarrow \bf{R}^+, \]

\begin{enumerate}
  \item $d(x, y) \geq 0 \; \forall x, y \in X$ (non-negativity)
  \item $d(x, y) = 0 \; iff \; x = y \; \forall x, y \in X$ (identity of indiscernables)
  \item $d(x, y) = d(y, x) \; \forall x, y \in X$ (symmetry)
  \item $d(x, z) \leq d(x, y) + d(y, z) \; \forall x, y, z \in X$ (triangle inequality)
\end{enumerate}


\noindent
(1) and (2) together produce \emph{positive definiteness}


\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Common-Area Metric}

\[ D(P, Q) = \int^1_0 \text{min}(P(x), Q(x)) \, dx \]

<<common_area_plot, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='5cm'>>=
theta_seq <- seq(0, 1, by = 0.0001);

P <- dbeta(theta_seq, 50, 50);
Q <- dbeta(theta_seq, 40, 60);

qplot(theta_seq, P, geom = 'line', xlab = expression(theta), ylab = 'Probability Density') +
    geom_line(aes(y = Q), colour = 'red') +
    geom_area(aes(x = theta_seq, y = pmin(P, Q)), fill = 'grey', alpha = 0.5);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Kullback-Leibler Divergence}

\[ D_{KL}(P||Q) = \int^1_0 p(x) \ln \frac{p(x)}{q(x)} \, dx \]

\begin{itemize}
  \item Not symmetric
  \item Does not obey Triangle Inequality
  \item Additional bits required to `correct' signal $P$ when using $Q$
\end{itemize}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Hellinger Distance}

\[ H^2(P, Q) = 1 - \int \sqrt{p(x) q(x)} \, dx \]

\[ 0 \leq H(P, Q) \leq 1 \]

\[ H^2(P, Q) \leq \delta(P, Q) \leq \sqrt{2} H(P, Q)  \]

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}
\[ \mu = 0.10 \;\; K_1 = 6,000 \;\; K_2 = 7,000 \;\; K_3 = 12,000 \]

<<distance_beta_distribution, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='5cm'>>=
mu <- 0.1;
K1 <- 6000;
K2 <- 7000;
K3 <- 12000;

x_seq <- seq(0.05, 0.15, by = 0.0001);

Beta1 <- dbeta(x_seq, mu * K1, (1 - mu) * K1);
Beta2 <- dbeta(x_seq, mu * K2, (1 - mu) * K2);
Beta3 <- dbeta(x_seq, mu * K3, (1 - mu) * K3);

staticmu_1_plot <- qplot(x_seq, Beta1, geom = 'line', xlab = expression(theta), ylab = 'Probability Density', ylim = c(0, 150)) +
    geom_line(aes(y = Beta2), colour = 'red') +
    geom_area(aes(x = x_seq, y = pmin(Beta1, Beta2)), fill = 'grey', alpha = 0.5);


staticmu_2_plot <- qplot(x_seq, Beta1, geom = 'line', xlab = expression(theta), ylab = 'Probability Density', ylim = c(0, 150)) +
    geom_line(aes(y = Beta3), colour = 'red') +
    geom_area(aes(x = x_seq, y = pmin(Beta1, Beta3)), fill = 'grey', alpha = 0.5);


grid.arrange(staticmu_1_plot, staticmu_2_plot, ncol = 2);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}

<<distance_beta_distribution_metrics_1, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
print(calculate_metrics(x_seq, Beta1, Beta1));
print(calculate_metrics(x_seq, Beta1, Beta2));
print(calculate_metrics(x_seq, Beta1, Beta3));
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}
\[ \mu_1 = 0.10 \;\; \mu_2 = 0.11 \;\; K_1 = 6,000 \;\; K_2 = 7,000 \;\; K_3 = 12,000 \]
<<distance_beta_distribution_metrics_2, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='4.5cm'>>=
x_seq <- seq(0, 1, by = 0.0001);
mu1 <- 0.10;
mu2 <- 0.11;
K1 <- 6000;
K2 <- 7000;
K3 <- 12000;

Beta1 <- dbeta(x_seq, (mu1 * K1),                     ((1 - mu1) * K1));
Beta2 <- dbeta(x_seq, (mu1 * K1) + (mu2 * (K2 - K1)), ((1 - mu1) * K1 + ((1 - mu2) * (K2 - K1))));
Beta3 <- dbeta(x_seq, (mu1 * K1) + (mu2 * (K3 - K1)), ((1 - mu1) * K1 + ((1 - mu2) * (K3 - K1))));

qplot(x_seq[x_seq >= 0.075 & x_seq <= 0.125], Beta1[x_seq >= 0.075 & x_seq <= 0.125], geom = 'line'
     , xlab = expression(theta), ylab = 'Probability Density') +
    geom_line(aes(y = Beta2[x_seq >= 0.075 & x_seq <= 0.125]), colour = 'red') +
    geom_line(aes(y = Beta3[x_seq >= 0.075 & x_seq <= 0.125]), colour = 'blue')
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}

<<distance_beta_distribution_metrics_3, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
print(calculate_metrics(x_seq, Beta1, Beta1));
print(calculate_metrics(x_seq, Beta1, Beta2));
print(calculate_metrics(x_seq, Beta1, Beta3));
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}
\[ \mu_1 = 0.10 \;\; \mu_2 = 0.15 \;\; K_1 = 6,000 \;\; K_2 = 7,000 \;\; K_3 = 12,000 \]
<<distance_beta_distribution_metrics_4, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='4.5cm'>>=
x_seq <- seq(0, 1, by = 0.0001);
mu1 <- 0.10;
mu2 <- 0.15;
K1 <- 6000;
K2 <- 7000;
K3 <- 12000;

Beta1 <- dbeta(x_seq, (mu1 * K1),                     ((1 - mu1) * K1));
Beta2 <- dbeta(x_seq, (mu1 * K1) + (mu2 * (K2 - K1)), ((1 - mu1) * K1 + ((1 - mu2) * (K2 - K1))));
Beta3 <- dbeta(x_seq, (mu1 * K1) + (mu2 * (K3 - K1)), ((1 - mu1) * K1 + ((1 - mu2) * (K3 - K1))));

qplot(x_seq[x_seq >= 0.075 & x_seq <= 0.150], Beta1[x_seq >= 0.075 & x_seq <= 0.150], geom = 'line'
     , xlab = expression(theta), ylab = 'Probability Density') +
    geom_line(aes(y = Beta2[x_seq >= 0.075 & x_seq <= 0.150]), colour = 'red') +
    geom_line(aes(y = Beta3[x_seq >= 0.075 & x_seq <= 0.150]), colour = 'blue')

@
\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Distance Values for Beta Distribution}

<<distance_beta_distribution_metrics_5, echo=TRUE, cache=FALSE, results='show', warning=FALSE, message=FALSE>>=
print(calculate_metrics(x_seq, Beta1, Beta1));
print(calculate_metrics(x_seq, Beta1, Beta2));
print(calculate_metrics(x_seq, Beta1, Beta3));
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Create Comparison Charts}

\[ \mu_1 = 0.10 \;\; \mu_2 = 0.15 \]

<<comparison_charts_1, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='4.5cm'>>=
postchange_data_dt <- stochastic_rate_count_data_dt[rate_date >= as.Date('2014-01-01'),
                                                    list(rate_date, a = cumsum(conversion_count), b = cumsum(month_count) - cumsum(conversion_count))];
postchange_plot_data_dt <- melt(postchange_data_dt[, data.table(t(calculate_postchange_metrics(init_mu = 0.1, init_K = 6000, a, b))), by = rate_date], 'rate_date');

qplot(rate_date, value, data = postchange_plot_data_dt, geom = 'line', xlab = 'Date', ylab = 'metric') +
    facet_wrap(~ variable, scale = 'free') +
    theme(axis.text.x = element_text(angle = 30, vjust = 0.5)) +
    expand_limits(y = 0);
@

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Create Comparison Charts}

\[ \mu_1 = 0.40 \;\; \mu_2 = 0.45 \]

<<comparison_charts_2, echo=FALSE, cache=FALSE, results='show', warning=FALSE, message=FALSE, out.height='4.5cm'>>=
highbase_postchange_data_dt <- highbase_count_data_dt[rate_date >= as.Date('2014-01-01')
                                                      ,list(rate_date, a=cumsum(conversion_count),b=cumsum(month_count)-cumsum(conversion_count))];

highbase_postchange_plot_data_dt <- melt(highbase_postchange_data_dt[,data.table(t(calculate_postchange_metrics(init_mu=0.4, init_K=6000, a, b))), by = rate_date], 'rate_date');

qplot(rate_date, value, data=highbase_postchange_plot_data_dt, geom='line', xlab='Date', ylab='metric') +
    facet_wrap(~ variable, scale='free') +
    theme(axis.text.x = element_text(angle = 30, vjust = 0.5)) +
    expand_limits(y = 0);
@

\end{frame}



%%%
%%%  Section: Summary and Conclusions
%%%

\section{Summary and Conclusions}

%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Summary}

\begin{itemize}
  \item Binomial process with known change point
  \item Use Beta distribution for simplicity
  \item Aggregate data in meaningful way (decay data as necessary)
  \item Track changes using `distance metric'
  \item Decide on thresholding (if necessary)
\end{itemize}

\end{frame}



%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Future Work}

\begin{itemize}
  \item Try with different distributions (Normal, Poisson, Multinomial)
  \item More comprehensive investigation of behaviour of distributions
  \item Randomised data to see patterns in metrics
  \item Look at statistical distance
  \item Time-series methods
\end{itemize}

\end{frame}





%%%
%%%  New Frame
%%%

\begin{frame}[fragile]{Summary}

\begin{center}

\href{mailto:michael.cooney@applied.ai}{michael.cooney@applied.ai}\\
\href{mailto:mickcooney@gmail.com}{mickcooney@gmail.com}

\vspace{3mm}

Slides and code available on github: \url{https://github.com/kaybenleroll/dublin_r_workshops}
\end{center}

\end{frame}




\end{document}
